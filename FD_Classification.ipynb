{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "8441ba02",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "8441ba02"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob\n",
        "import cv2 as cv\n",
        "# import seaborn as sns\n",
        "import pandas as pd\n",
        "from skimage.filters import sobel\n",
        "from skimage.feature import greycomatrix, greycoprops\n",
        "from skimage.measure import shannon_entropy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "from PIL import Image\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"dataset.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPNlezQe-wfU",
        "outputId": "810832d8-a4ef-4a74-8e09-4e09a37fded3"
      },
      "id": "yPNlezQe-wfU",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = \"datatest.zip\"\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "naylC-4LXtt7",
        "outputId": "aad4f6fb-eb6d-48b6-9aaa-704747655962"
      },
      "id": "naylC-4LXtt7",
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "03c781e1",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "03c781e1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "3fb6b4a7",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "3fb6b4a7",
        "outputId": "13a47c49-b813-4ca3-d0e0-344826c332d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Energy_0    Corr_0  Homogen_0  Contrast_0     ASM_0  Energy_45  \\\n",
              "0           0  0.360166  0.849100   0.715262  400.557698  0.129720   0.352685   \n",
              "1           0  0.400987  0.812333   0.749640  407.428869  0.160791   0.408181   \n",
              "2           0  0.376491  0.877119   0.798621  690.161206  0.141746   0.378780   \n",
              "3           0  0.348277  0.832274   0.694796  652.404336  0.121297   0.349204   \n",
              "4           0  0.362457  0.895325   0.755612  431.792027  0.131375   0.321500   \n",
              "\n",
              "    Corr_45  Homogen_45  Contrast_45  ...  Homogen_90  Contrast_90    ASM_90  \\\n",
              "0  0.830636    0.695192   449.911262  ...    0.697137   444.862077  0.129720   \n",
              "1  0.835459    0.768635   358.929444  ...    0.721557   478.110919  0.160791   \n",
              "2  0.881331    0.804157   665.580926  ...    0.821744   582.173172  0.141746   \n",
              "3  0.834127    0.699276   647.042470  ...    0.707651   618.055012  0.121297   \n",
              "4  0.830256    0.627472   697.592628  ...    0.627253   695.672415  0.131375   \n",
              "\n",
              "   Energy_135  Corr_135  Homogen_135  Contrast_135   ASM_135  output  \\\n",
              "0    0.371847  0.867505     0.744380    352.059009  0.129720       0   \n",
              "1    0.392616  0.782994     0.729269    473.488716  0.160791       0   \n",
              "2    0.374711  0.873295     0.793183    711.160952  0.141746       0   \n",
              "3    0.360706  0.865813     0.734265    523.300701  0.121297       0   \n",
              "4    0.325453  0.848361     0.642111    623.203608  0.131375       0   \n",
              "\n",
              "               filenames  \n",
              "0   dataset\\0\\fish_0.jpg  \n",
              "1   dataset\\0\\fish_1.jpg  \n",
              "2  dataset\\0\\fish_10.jpg  \n",
              "3  dataset\\0\\fish_11.jpg  \n",
              "4  dataset\\0\\fish_12.jpg  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2c081d54-0e90-4024-9f2c-d029f5517747\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Energy_0</th>\n",
              "      <th>Corr_0</th>\n",
              "      <th>Homogen_0</th>\n",
              "      <th>Contrast_0</th>\n",
              "      <th>ASM_0</th>\n",
              "      <th>Energy_45</th>\n",
              "      <th>Corr_45</th>\n",
              "      <th>Homogen_45</th>\n",
              "      <th>Contrast_45</th>\n",
              "      <th>...</th>\n",
              "      <th>Homogen_90</th>\n",
              "      <th>Contrast_90</th>\n",
              "      <th>ASM_90</th>\n",
              "      <th>Energy_135</th>\n",
              "      <th>Corr_135</th>\n",
              "      <th>Homogen_135</th>\n",
              "      <th>Contrast_135</th>\n",
              "      <th>ASM_135</th>\n",
              "      <th>output</th>\n",
              "      <th>filenames</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.360166</td>\n",
              "      <td>0.849100</td>\n",
              "      <td>0.715262</td>\n",
              "      <td>400.557698</td>\n",
              "      <td>0.129720</td>\n",
              "      <td>0.352685</td>\n",
              "      <td>0.830636</td>\n",
              "      <td>0.695192</td>\n",
              "      <td>449.911262</td>\n",
              "      <td>...</td>\n",
              "      <td>0.697137</td>\n",
              "      <td>444.862077</td>\n",
              "      <td>0.129720</td>\n",
              "      <td>0.371847</td>\n",
              "      <td>0.867505</td>\n",
              "      <td>0.744380</td>\n",
              "      <td>352.059009</td>\n",
              "      <td>0.129720</td>\n",
              "      <td>0</td>\n",
              "      <td>dataset\\0\\fish_0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.400987</td>\n",
              "      <td>0.812333</td>\n",
              "      <td>0.749640</td>\n",
              "      <td>407.428869</td>\n",
              "      <td>0.160791</td>\n",
              "      <td>0.408181</td>\n",
              "      <td>0.835459</td>\n",
              "      <td>0.768635</td>\n",
              "      <td>358.929444</td>\n",
              "      <td>...</td>\n",
              "      <td>0.721557</td>\n",
              "      <td>478.110919</td>\n",
              "      <td>0.160791</td>\n",
              "      <td>0.392616</td>\n",
              "      <td>0.782994</td>\n",
              "      <td>0.729269</td>\n",
              "      <td>473.488716</td>\n",
              "      <td>0.160791</td>\n",
              "      <td>0</td>\n",
              "      <td>dataset\\0\\fish_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.376491</td>\n",
              "      <td>0.877119</td>\n",
              "      <td>0.798621</td>\n",
              "      <td>690.161206</td>\n",
              "      <td>0.141746</td>\n",
              "      <td>0.378780</td>\n",
              "      <td>0.881331</td>\n",
              "      <td>0.804157</td>\n",
              "      <td>665.580926</td>\n",
              "      <td>...</td>\n",
              "      <td>0.821744</td>\n",
              "      <td>582.173172</td>\n",
              "      <td>0.141746</td>\n",
              "      <td>0.374711</td>\n",
              "      <td>0.873295</td>\n",
              "      <td>0.793183</td>\n",
              "      <td>711.160952</td>\n",
              "      <td>0.141746</td>\n",
              "      <td>0</td>\n",
              "      <td>dataset\\0\\fish_10.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.348277</td>\n",
              "      <td>0.832274</td>\n",
              "      <td>0.694796</td>\n",
              "      <td>652.404336</td>\n",
              "      <td>0.121297</td>\n",
              "      <td>0.349204</td>\n",
              "      <td>0.834127</td>\n",
              "      <td>0.699276</td>\n",
              "      <td>647.042470</td>\n",
              "      <td>...</td>\n",
              "      <td>0.707651</td>\n",
              "      <td>618.055012</td>\n",
              "      <td>0.121297</td>\n",
              "      <td>0.360706</td>\n",
              "      <td>0.865813</td>\n",
              "      <td>0.734265</td>\n",
              "      <td>523.300701</td>\n",
              "      <td>0.121297</td>\n",
              "      <td>0</td>\n",
              "      <td>dataset\\0\\fish_11.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.362457</td>\n",
              "      <td>0.895325</td>\n",
              "      <td>0.755612</td>\n",
              "      <td>431.792027</td>\n",
              "      <td>0.131375</td>\n",
              "      <td>0.321500</td>\n",
              "      <td>0.830256</td>\n",
              "      <td>0.627472</td>\n",
              "      <td>697.592628</td>\n",
              "      <td>...</td>\n",
              "      <td>0.627253</td>\n",
              "      <td>695.672415</td>\n",
              "      <td>0.131375</td>\n",
              "      <td>0.325453</td>\n",
              "      <td>0.848361</td>\n",
              "      <td>0.642111</td>\n",
              "      <td>623.203608</td>\n",
              "      <td>0.131375</td>\n",
              "      <td>0</td>\n",
              "      <td>dataset\\0\\fish_12.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2c081d54-0e90-4024-9f2c-d029f5517747')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2c081d54-0e90-4024-9f2c-d029f5517747 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2c081d54-0e90-4024-9f2c-d029f5517747');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "df = pd.read_csv(\"features.csv\")\n",
        "dt = pd.read_csv(\"Data_test.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "af682c24",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "af682c24",
        "outputId": "7b550838-f69d-4aa8-a81d-31d005ac9d90"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Energy_0    Corr_0  Homogen_0  Contrast_0     ASM_0  Energy_45   Corr_45  \\\n",
              "0  0.360166  0.849100   0.715262  400.557698  0.129720   0.352685  0.830636   \n",
              "1  0.400987  0.812333   0.749640  407.428869  0.160791   0.408181  0.835459   \n",
              "2  0.376491  0.877119   0.798621  690.161206  0.141746   0.378780  0.881331   \n",
              "3  0.348277  0.832274   0.694796  652.404336  0.121297   0.349204  0.834127   \n",
              "4  0.362457  0.895325   0.755612  431.792027  0.131375   0.321500  0.830256   \n",
              "\n",
              "   Homogen_45  Contrast_45    ASM_45  ...   Corr_90  Homogen_90  Contrast_90  \\\n",
              "0    0.695192   449.911262  0.129720  ...  0.832495    0.697137   444.862077   \n",
              "1    0.768635   358.929444  0.160791  ...  0.781798    0.721557   478.110919   \n",
              "2    0.804157   665.580926  0.141746  ...  0.896054    0.821744   582.173172   \n",
              "3    0.699276   647.042470  0.121297  ...  0.842687    0.707651   618.055012   \n",
              "4    0.627472   697.592628  0.131375  ...  0.830514    0.627253   695.672415   \n",
              "\n",
              "     ASM_90  Energy_135  Corr_135  Homogen_135  Contrast_135   ASM_135  output  \n",
              "0  0.129720    0.371847  0.867505     0.744380    352.059009  0.129720       0  \n",
              "1  0.160791    0.392616  0.782994     0.729269    473.488716  0.160791       0  \n",
              "2  0.141746    0.374711  0.873295     0.793183    711.160952  0.141746       0  \n",
              "3  0.121297    0.360706  0.865813     0.734265    523.300701  0.121297       0  \n",
              "4  0.131375    0.325453  0.848361     0.642111    623.203608  0.131375       0  \n",
              "\n",
              "[5 rows x 21 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-10001859-36f1-46ea-94b3-4fc77572c3c4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Energy_0</th>\n",
              "      <th>Corr_0</th>\n",
              "      <th>Homogen_0</th>\n",
              "      <th>Contrast_0</th>\n",
              "      <th>ASM_0</th>\n",
              "      <th>Energy_45</th>\n",
              "      <th>Corr_45</th>\n",
              "      <th>Homogen_45</th>\n",
              "      <th>Contrast_45</th>\n",
              "      <th>ASM_45</th>\n",
              "      <th>...</th>\n",
              "      <th>Corr_90</th>\n",
              "      <th>Homogen_90</th>\n",
              "      <th>Contrast_90</th>\n",
              "      <th>ASM_90</th>\n",
              "      <th>Energy_135</th>\n",
              "      <th>Corr_135</th>\n",
              "      <th>Homogen_135</th>\n",
              "      <th>Contrast_135</th>\n",
              "      <th>ASM_135</th>\n",
              "      <th>output</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.360166</td>\n",
              "      <td>0.849100</td>\n",
              "      <td>0.715262</td>\n",
              "      <td>400.557698</td>\n",
              "      <td>0.129720</td>\n",
              "      <td>0.352685</td>\n",
              "      <td>0.830636</td>\n",
              "      <td>0.695192</td>\n",
              "      <td>449.911262</td>\n",
              "      <td>0.129720</td>\n",
              "      <td>...</td>\n",
              "      <td>0.832495</td>\n",
              "      <td>0.697137</td>\n",
              "      <td>444.862077</td>\n",
              "      <td>0.129720</td>\n",
              "      <td>0.371847</td>\n",
              "      <td>0.867505</td>\n",
              "      <td>0.744380</td>\n",
              "      <td>352.059009</td>\n",
              "      <td>0.129720</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.400987</td>\n",
              "      <td>0.812333</td>\n",
              "      <td>0.749640</td>\n",
              "      <td>407.428869</td>\n",
              "      <td>0.160791</td>\n",
              "      <td>0.408181</td>\n",
              "      <td>0.835459</td>\n",
              "      <td>0.768635</td>\n",
              "      <td>358.929444</td>\n",
              "      <td>0.160791</td>\n",
              "      <td>...</td>\n",
              "      <td>0.781798</td>\n",
              "      <td>0.721557</td>\n",
              "      <td>478.110919</td>\n",
              "      <td>0.160791</td>\n",
              "      <td>0.392616</td>\n",
              "      <td>0.782994</td>\n",
              "      <td>0.729269</td>\n",
              "      <td>473.488716</td>\n",
              "      <td>0.160791</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.376491</td>\n",
              "      <td>0.877119</td>\n",
              "      <td>0.798621</td>\n",
              "      <td>690.161206</td>\n",
              "      <td>0.141746</td>\n",
              "      <td>0.378780</td>\n",
              "      <td>0.881331</td>\n",
              "      <td>0.804157</td>\n",
              "      <td>665.580926</td>\n",
              "      <td>0.141746</td>\n",
              "      <td>...</td>\n",
              "      <td>0.896054</td>\n",
              "      <td>0.821744</td>\n",
              "      <td>582.173172</td>\n",
              "      <td>0.141746</td>\n",
              "      <td>0.374711</td>\n",
              "      <td>0.873295</td>\n",
              "      <td>0.793183</td>\n",
              "      <td>711.160952</td>\n",
              "      <td>0.141746</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.348277</td>\n",
              "      <td>0.832274</td>\n",
              "      <td>0.694796</td>\n",
              "      <td>652.404336</td>\n",
              "      <td>0.121297</td>\n",
              "      <td>0.349204</td>\n",
              "      <td>0.834127</td>\n",
              "      <td>0.699276</td>\n",
              "      <td>647.042470</td>\n",
              "      <td>0.121297</td>\n",
              "      <td>...</td>\n",
              "      <td>0.842687</td>\n",
              "      <td>0.707651</td>\n",
              "      <td>618.055012</td>\n",
              "      <td>0.121297</td>\n",
              "      <td>0.360706</td>\n",
              "      <td>0.865813</td>\n",
              "      <td>0.734265</td>\n",
              "      <td>523.300701</td>\n",
              "      <td>0.121297</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.362457</td>\n",
              "      <td>0.895325</td>\n",
              "      <td>0.755612</td>\n",
              "      <td>431.792027</td>\n",
              "      <td>0.131375</td>\n",
              "      <td>0.321500</td>\n",
              "      <td>0.830256</td>\n",
              "      <td>0.627472</td>\n",
              "      <td>697.592628</td>\n",
              "      <td>0.131375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.830514</td>\n",
              "      <td>0.627253</td>\n",
              "      <td>695.672415</td>\n",
              "      <td>0.131375</td>\n",
              "      <td>0.325453</td>\n",
              "      <td>0.848361</td>\n",
              "      <td>0.642111</td>\n",
              "      <td>623.203608</td>\n",
              "      <td>0.131375</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 21 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-10001859-36f1-46ea-94b3-4fc77572c3c4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-10001859-36f1-46ea-94b3-4fc77572c3c4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-10001859-36f1-46ea-94b3-4fc77572c3c4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "df.drop(['filenames'], axis=1, inplace=True)\n",
        "df.drop(['Unnamed: 0'], axis=1, inplace=True)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "037c422e",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "037c422e",
        "outputId": "cb10143c-2bc0-4aef-c031-cc9471b79d26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1    27\n",
            "0    26\n",
            "2    16\n",
            "3    14\n",
            "Name: output, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "label_distr = df['output'].value_counts()\n",
        "\n",
        "label_name = ['Normal', 'RS', 'MAS', 'WS']\n",
        "\n",
        "print(label_distr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "ee848072",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "ee848072"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils.np_utils import to_categorical\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn import preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "2ee0a682",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "2ee0a682"
      },
      "outputs": [],
      "source": [
        "def decimal_scaling(data):\n",
        "    data = np.array(data, dtype=np.float32)\n",
        "    max_row = data.max(axis=0)\n",
        "    c = np.array([len(str(int(number))) for number in np.abs(max_row)])\n",
        "    return data / (10 ** c)\n",
        "\n",
        "\n",
        "X = decimal_scaling(df[['Energy_0', 'Corr_0', 'Homogen_0', 'Contrast_0', 'ASM_0',\n",
        "                        'Energy_45', 'Corr_45', 'Homogen_45', 'Contrast_45', 'ASM_45',\n",
        "                        'Energy_90', 'Corr_90', 'Homogen_90', 'Contrast_90', 'ASM_90',\n",
        "                        'Energy_135', 'Corr_135', 'Homogen_135', 'Contrast_135', 'ASM_135']].values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "id": "dd8d281f",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd8d281f",
        "outputId": "cd787bf6-27d5-4570-d11b-3638b05e69ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " categorical label : \n",
            " [0 1 2 3]\n",
            "\n",
            "\n",
            " one hot encoding for sample 0 : \n",
            " [1. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(df[\"output\"].values)\n",
        "\n",
        "print(\" categorical label : \\n\", le.classes_)\n",
        "\n",
        "Y = le.transform(df['output'].values)\n",
        "Y = to_categorical(Y)\n",
        "\n",
        "print(\"\\n\\n one hot encoding for sample 0 : \\n\", Y[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "id": "e7b35b84",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e7b35b84",
        "outputId": "b478c4c9-de67-4300-ebfe-ac95a35b75f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensi data :\n",
            "\n",
            "X train \t X test \t Y train \t Y test\n",
            "(66, 20) \t (17, 20) \t (66, 4) \t (17, 4)\n"
          ]
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2,random_state=42)\n",
        "\n",
        "print(\"Dimensi data :\\n\")\n",
        "print(\"X train \\t X test \\t Y train \\t Y test\")\n",
        "print(\"%s \\t %s \\t %s \\t %s\" % (X_train.shape, X_test.shape, y_train.shape, y_test.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "id": "b69e2e6b",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "b69e2e6b"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "import keras\n",
        "from keras import backend as K"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "id": "14424bb3",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "14424bb3"
      },
      "outputs": [],
      "source": [
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "\n",
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "\n",
        "def nn_model(max_len):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(32,\n",
        "                    activation=\"elu\",\n",
        "                    input_shape=(max_len,)))\n",
        "    model.add(Dense(128, activation=\"elu\"))\n",
        "    model.add(Dense(64, activation=\"elu\"))\n",
        "    model.add(Dense(32, activation=\"elu\"))\n",
        "    model.add(Dense(16, activation=\"elu\"))\n",
        "    model.add(Dense(4))\n",
        "    model.add(Activation(\"sigmoid\"))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy', precision, recall])\n",
        "    return model\n",
        "\n",
        "\n",
        "def check_model(model_, x, y, x_val, y_val, epochs_, batch_size_):\n",
        "    hist = model_.fit(x,\n",
        "                      y,\n",
        "                      epochs=epochs_,\n",
        "                      batch_size=batch_size_,\n",
        "                      validation_data=(x_val, y_val))\n",
        "    return hist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "802b6f8b",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "802b6f8b",
        "outputId": "d3b45ed7-79d8-4512-91d6-dd0b0b6984ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 32)                672       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,828\n",
            "Trainable params: 15,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "3/3 [==============================] - 1s 140ms/step - loss: 1.3845 - accuracy: 0.3030 - precision: 0.3125 - recall: 0.1774 - val_loss: 1.3518 - val_accuracy: 0.3529 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 2/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3628 - accuracy: 0.3485 - precision: 0.4271 - recall: 0.2117 - val_loss: 1.3286 - val_accuracy: 0.3529 - val_precision: 0.7059 - val_recall: 0.3636\n",
            "Epoch 3/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.3486 - accuracy: 0.3333 - precision: 0.7292 - recall: 0.3693 - val_loss: 1.3283 - val_accuracy: 0.3529 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 4/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3450 - accuracy: 0.3333 - precision: 0.3854 - recall: 0.2073 - val_loss: 1.3246 - val_accuracy: 0.3529 - val_precision: 0.7059 - val_recall: 0.3636\n",
            "Epoch 5/500\n",
            "3/3 [==============================] - 0s 15ms/step - loss: 1.3376 - accuracy: 0.3333 - precision: 0.6979 - recall: 0.3642 - val_loss: 1.3278 - val_accuracy: 0.3529 - val_precision: 0.7059 - val_recall: 0.3636\n",
            "Epoch 6/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3331 - accuracy: 0.3333 - precision: 0.7188 - recall: 0.3688 - val_loss: 1.3228 - val_accuracy: 0.3529 - val_precision: 0.7059 - val_recall: 0.3529\n",
            "Epoch 7/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.3299 - accuracy: 0.3333 - precision: 0.5729 - recall: 0.2916 - val_loss: 1.3209 - val_accuracy: 0.3529 - val_precision: 0.7059 - val_recall: 0.3333\n",
            "Epoch 8/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.3301 - accuracy: 0.3333 - precision: 0.5729 - recall: 0.2894 - val_loss: 1.3280 - val_accuracy: 0.3529 - val_precision: 0.7647 - val_recall: 0.3023\n",
            "Epoch 9/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3346 - accuracy: 0.3333 - precision: 0.8750 - recall: 0.3237 - val_loss: 1.3398 - val_accuracy: 0.3529 - val_precision: 0.7647 - val_recall: 0.2653\n",
            "Epoch 10/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.3350 - accuracy: 0.3333 - precision: 0.6875 - recall: 0.2419 - val_loss: 1.3432 - val_accuracy: 0.3529 - val_precision: 0.7647 - val_recall: 0.2600\n",
            "Epoch 11/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3249 - accuracy: 0.3333 - precision: 0.7083 - recall: 0.2450 - val_loss: 1.3419 - val_accuracy: 0.3529 - val_precision: 0.7647 - val_recall: 0.2600\n",
            "Epoch 12/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3190 - accuracy: 0.3333 - precision: 0.8542 - recall: 0.3165 - val_loss: 1.3478 - val_accuracy: 0.3529 - val_precision: 0.7647 - val_recall: 0.2766\n",
            "Epoch 13/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3124 - accuracy: 0.3333 - precision: 0.5417 - recall: 0.1937 - val_loss: 1.3464 - val_accuracy: 0.3529 - val_precision: 0.7647 - val_recall: 0.2826\n",
            "Epoch 14/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.3108 - accuracy: 0.3333 - precision: 0.7083 - recall: 0.2671 - val_loss: 1.3349 - val_accuracy: 0.4706 - val_precision: 0.7647 - val_recall: 0.2766\n",
            "Epoch 15/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3050 - accuracy: 0.3939 - precision: 0.8854 - recall: 0.3097 - val_loss: 1.3124 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3043\n",
            "Epoch 16/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3032 - accuracy: 0.3182 - precision: 0.9167 - recall: 0.3806 - val_loss: 1.2907 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.3684\n",
            "Epoch 17/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3065 - accuracy: 0.3333 - precision: 0.8021 - recall: 0.3819 - val_loss: 1.2738 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3714\n",
            "Epoch 18/500\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.3157 - accuracy: 0.3030 - precision: 0.6042 - recall: 0.3006 - val_loss: 1.2699 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 19/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.3411 - accuracy: 0.3030 - precision: 0.5833 - recall: 0.2868 - val_loss: 1.2758 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 20/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.3501 - accuracy: 0.3030 - precision: 0.5938 - recall: 0.2762 - val_loss: 1.2743 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 21/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3320 - accuracy: 0.3333 - precision: 0.5938 - recall: 0.2988 - val_loss: 1.2747 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3939\n",
            "Epoch 22/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.3165 - accuracy: 0.3485 - precision: 0.7604 - recall: 0.3816 - val_loss: 1.2833 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3939\n",
            "Epoch 23/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3045 - accuracy: 0.3333 - precision: 0.6042 - recall: 0.2905 - val_loss: 1.2880 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3714\n",
            "Epoch 24/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.3007 - accuracy: 0.3333 - precision: 0.5833 - recall: 0.2904 - val_loss: 1.2889 - val_accuracy: 0.4706 - val_precision: 0.7647 - val_recall: 0.3714\n",
            "Epoch 25/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2973 - accuracy: 0.3182 - precision: 0.7500 - recall: 0.3702 - val_loss: 1.2794 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3939\n",
            "Epoch 26/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2948 - accuracy: 0.3485 - precision: 0.4375 - recall: 0.2137 - val_loss: 1.2725 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3611\n",
            "Epoch 27/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2915 - accuracy: 0.3636 - precision: 0.6250 - recall: 0.2758 - val_loss: 1.2778 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.3415\n",
            "Epoch 28/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2901 - accuracy: 0.3485 - precision: 0.8646 - recall: 0.3513 - val_loss: 1.2839 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.3256\n",
            "Epoch 29/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2904 - accuracy: 0.3485 - precision: 0.8958 - recall: 0.3752 - val_loss: 1.2901 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.3043\n",
            "Epoch 30/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2907 - accuracy: 0.3485 - precision: 0.7500 - recall: 0.2596 - val_loss: 1.2870 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.3111\n",
            "Epoch 31/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2862 - accuracy: 0.3485 - precision: 0.8958 - recall: 0.3334 - val_loss: 1.2760 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.3333\n",
            "Epoch 32/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2790 - accuracy: 0.3333 - precision: 0.8646 - recall: 0.3766 - val_loss: 1.2595 - val_accuracy: 0.5882 - val_precision: 0.7647 - val_recall: 0.3333\n",
            "Epoch 33/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.2766 - accuracy: 0.3939 - precision: 0.8229 - recall: 0.3495 - val_loss: 1.2409 - val_accuracy: 0.5882 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 34/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2776 - accuracy: 0.4545 - precision: 0.7604 - recall: 0.3419 - val_loss: 1.2268 - val_accuracy: 0.5882 - val_precision: 0.7647 - val_recall: 0.3939\n",
            "Epoch 35/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2777 - accuracy: 0.4697 - precision: 0.5938 - recall: 0.2936 - val_loss: 1.2197 - val_accuracy: 0.6471 - val_precision: 0.7647 - val_recall: 0.3939\n",
            "Epoch 36/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2791 - accuracy: 0.4242 - precision: 0.7500 - recall: 0.3718 - val_loss: 1.2163 - val_accuracy: 0.5294 - val_precision: 0.7647 - val_recall: 0.3939\n",
            "Epoch 37/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 1.2837 - accuracy: 0.4394 - precision: 0.7500 - recall: 0.3718 - val_loss: 1.2102 - val_accuracy: 0.4706 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 38/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.2875 - accuracy: 0.4091 - precision: 0.7500 - recall: 0.3718 - val_loss: 1.2049 - val_accuracy: 0.4706 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 39/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 1.2950 - accuracy: 0.3788 - precision: 0.5938 - recall: 0.2936 - val_loss: 1.2045 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 40/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.2983 - accuracy: 0.3636 - precision: 0.5833 - recall: 0.2917 - val_loss: 1.2036 - val_accuracy: 0.4706 - val_precision: 0.7647 - val_recall: 0.3939\n",
            "Epoch 41/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.2837 - accuracy: 0.4394 - precision: 0.5938 - recall: 0.2954 - val_loss: 1.2102 - val_accuracy: 0.5882 - val_precision: 0.7647 - val_recall: 0.3939\n",
            "Epoch 42/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.2683 - accuracy: 0.4697 - precision: 0.7500 - recall: 0.3718 - val_loss: 1.2247 - val_accuracy: 0.5882 - val_precision: 0.7647 - val_recall: 0.3611\n",
            "Epoch 43/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2637 - accuracy: 0.4394 - precision: 0.7917 - recall: 0.3458 - val_loss: 1.2349 - val_accuracy: 0.5882 - val_precision: 0.7647 - val_recall: 0.3250\n",
            "Epoch 44/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2644 - accuracy: 0.3485 - precision: 0.5312 - recall: 0.2266 - val_loss: 1.2413 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3415\n",
            "Epoch 45/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2610 - accuracy: 0.4091 - precision: 0.8646 - recall: 0.3831 - val_loss: 1.2522 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3500\n",
            "Epoch 46/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2586 - accuracy: 0.4545 - precision: 0.8229 - recall: 0.3482 - val_loss: 1.2650 - val_accuracy: 0.5882 - val_precision: 0.7647 - val_recall: 0.3514\n",
            "Epoch 47/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2569 - accuracy: 0.4545 - precision: 0.8125 - recall: 0.3302 - val_loss: 1.2766 - val_accuracy: 0.5882 - val_precision: 0.7647 - val_recall: 0.3421\n",
            "Epoch 48/500\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2571 - accuracy: 0.4697 - precision: 0.6771 - recall: 0.2791 - val_loss: 1.2921 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3784\n",
            "Epoch 49/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2616 - accuracy: 0.4545 - precision: 0.6667 - recall: 0.3042 - val_loss: 1.3112 - val_accuracy: 0.7059 - val_precision: 0.7647 - val_recall: 0.3421\n",
            "Epoch 50/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2670 - accuracy: 0.4545 - precision: 0.8333 - recall: 0.3766 - val_loss: 1.3124 - val_accuracy: 0.6471 - val_precision: 0.7647 - val_recall: 0.3421\n",
            "Epoch 51/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2609 - accuracy: 0.4545 - precision: 0.8333 - recall: 0.3334 - val_loss: 1.3068 - val_accuracy: 0.5882 - val_precision: 0.7647 - val_recall: 0.3421\n",
            "Epoch 52/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2572 - accuracy: 0.4697 - precision: 0.8438 - recall: 0.3094 - val_loss: 1.3097 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.3256\n",
            "Epoch 53/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.2643 - accuracy: 0.4545 - precision: 0.8646 - recall: 0.3265 - val_loss: 1.3062 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3111\n",
            "Epoch 54/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2595 - accuracy: 0.4697 - precision: 0.8646 - recall: 0.3044 - val_loss: 1.2829 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3111\n",
            "Epoch 55/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2514 - accuracy: 0.4848 - precision: 0.8646 - recall: 0.3030 - val_loss: 1.2578 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3256\n",
            "Epoch 56/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.2447 - accuracy: 0.4697 - precision: 0.8646 - recall: 0.3210 - val_loss: 1.2385 - val_accuracy: 0.4706 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 57/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.2446 - accuracy: 0.4242 - precision: 0.8125 - recall: 0.4493 - val_loss: 1.2396 - val_accuracy: 0.4118 - val_precision: 0.7059 - val_recall: 0.3750\n",
            "Epoch 58/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2567 - accuracy: 0.3788 - precision: 0.4479 - recall: 0.2444 - val_loss: 1.2362 - val_accuracy: 0.4118 - val_precision: 0.7059 - val_recall: 0.3871\n",
            "Epoch 59/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2584 - accuracy: 0.3636 - precision: 0.6250 - recall: 0.3280 - val_loss: 1.2355 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3684\n",
            "Epoch 60/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2477 - accuracy: 0.4545 - precision: 0.8646 - recall: 0.3192 - val_loss: 1.2710 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3043\n",
            "Epoch 61/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.2509 - accuracy: 0.5152 - precision: 0.8646 - recall: 0.2999 - val_loss: 1.2863 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3043\n",
            "Epoch 62/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.2549 - accuracy: 0.5152 - precision: 0.8646 - recall: 0.3021 - val_loss: 1.3209 - val_accuracy: 0.3529 - val_precision: 0.8235 - val_recall: 0.3111\n",
            "Epoch 63/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2653 - accuracy: 0.4242 - precision: 0.8646 - recall: 0.3066 - val_loss: 1.3305 - val_accuracy: 0.2941 - val_precision: 0.8235 - val_recall: 0.3256\n",
            "Epoch 64/500\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2655 - accuracy: 0.3788 - precision: 0.8646 - recall: 0.3098 - val_loss: 1.3054 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.3256\n",
            "Epoch 65/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2538 - accuracy: 0.4697 - precision: 0.8646 - recall: 0.3301 - val_loss: 1.2812 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.3111\n",
            "Epoch 66/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2427 - accuracy: 0.4848 - precision: 0.7083 - recall: 0.2648 - val_loss: 1.2318 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3182\n",
            "Epoch 67/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2273 - accuracy: 0.4697 - precision: 0.8646 - recall: 0.3348 - val_loss: 1.1821 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 68/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2249 - accuracy: 0.4697 - precision: 0.8333 - recall: 0.3615 - val_loss: 1.1684 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.4194\n",
            "Epoch 69/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2592 - accuracy: 0.3939 - precision: 0.7083 - recall: 0.4366 - val_loss: 1.1707 - val_accuracy: 0.4118 - val_precision: 0.7059 - val_recall: 0.4444\n",
            "Epoch 70/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2879 - accuracy: 0.3788 - precision: 0.6979 - recall: 0.3517 - val_loss: 1.1522 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.4643\n",
            "Epoch 71/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2655 - accuracy: 0.3939 - precision: 0.7083 - recall: 0.3334 - val_loss: 1.1169 - val_accuracy: 0.7647 - val_precision: 0.7647 - val_recall: 0.3514\n",
            "Epoch 72/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2316 - accuracy: 0.4545 - precision: 0.6979 - recall: 0.2943 - val_loss: 1.1405 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3415\n",
            "Epoch 73/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.2423 - accuracy: 0.3939 - precision: 0.7396 - recall: 0.3110 - val_loss: 1.1288 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3415\n",
            "Epoch 74/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2274 - accuracy: 0.4242 - precision: 0.8958 - recall: 0.3981 - val_loss: 1.1239 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3415\n",
            "Epoch 75/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2167 - accuracy: 0.4091 - precision: 0.8854 - recall: 0.3452 - val_loss: 1.1366 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3500\n",
            "Epoch 76/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2136 - accuracy: 0.3939 - precision: 0.8854 - recall: 0.3570 - val_loss: 1.1520 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3333\n",
            "Epoch 77/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.2147 - accuracy: 0.3485 - precision: 0.7292 - recall: 0.2820 - val_loss: 1.1608 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3333\n",
            "Epoch 78/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2164 - accuracy: 0.3636 - precision: 0.8958 - recall: 0.4466 - val_loss: 1.1714 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.3333\n",
            "Epoch 79/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2196 - accuracy: 0.3485 - precision: 0.9062 - recall: 0.3651 - val_loss: 1.1442 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3333\n",
            "Epoch 80/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2124 - accuracy: 0.3485 - precision: 0.8854 - recall: 0.3568 - val_loss: 1.1119 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3590\n",
            "Epoch 81/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.1997 - accuracy: 0.3939 - precision: 0.8854 - recall: 0.3647 - val_loss: 1.1119 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3500\n",
            "Epoch 82/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.2086 - accuracy: 0.3636 - precision: 0.8958 - recall: 0.3363 - val_loss: 1.1362 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.3415\n",
            "Epoch 83/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2231 - accuracy: 0.3636 - precision: 0.8958 - recall: 0.3543 - val_loss: 1.1509 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.3256\n",
            "Epoch 84/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2322 - accuracy: 0.3485 - precision: 0.7500 - recall: 0.2956 - val_loss: 1.0869 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3590\n",
            "Epoch 85/500\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.2002 - accuracy: 0.4091 - precision: 0.7292 - recall: 0.3216 - val_loss: 1.0218 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.3810\n",
            "Epoch 86/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.2181 - accuracy: 0.4545 - precision: 0.7812 - recall: 0.3233 - val_loss: 1.0696 - val_accuracy: 0.4706 - val_precision: 0.8824 - val_recall: 0.3947\n",
            "Epoch 87/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.3111 - accuracy: 0.3788 - precision: 0.7604 - recall: 0.3552 - val_loss: 1.0830 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 88/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.2926 - accuracy: 0.3939 - precision: 0.6146 - recall: 0.2808 - val_loss: 1.0238 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 89/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.1928 - accuracy: 0.4394 - precision: 0.6458 - recall: 0.2950 - val_loss: 1.1054 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.3500\n",
            "Epoch 90/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.2014 - accuracy: 0.3636 - precision: 0.8958 - recall: 0.3907 - val_loss: 1.2281 - val_accuracy: 0.3529 - val_precision: 0.7647 - val_recall: 0.3714\n",
            "Epoch 91/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.2603 - accuracy: 0.3182 - precision: 0.6562 - recall: 0.3370 - val_loss: 1.2196 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3611\n",
            "Epoch 92/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2203 - accuracy: 0.3182 - precision: 0.8750 - recall: 0.4060 - val_loss: 1.1226 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3590\n",
            "Epoch 93/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.1663 - accuracy: 0.4394 - precision: 0.7292 - recall: 0.3300 - val_loss: 1.0659 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 94/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.1978 - accuracy: 0.4242 - precision: 0.7812 - recall: 0.3456 - val_loss: 1.0960 - val_accuracy: 0.4118 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 95/500\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.2892 - accuracy: 0.4091 - precision: 0.6042 - recall: 0.2993 - val_loss: 1.1078 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 96/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.2940 - accuracy: 0.4091 - precision: 0.7604 - recall: 0.3769 - val_loss: 1.0823 - val_accuracy: 0.4706 - val_precision: 0.9412 - val_recall: 0.4848\n",
            "Epoch 97/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.2115 - accuracy: 0.4242 - precision: 0.7188 - recall: 0.3192 - val_loss: 1.0998 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 98/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.1719 - accuracy: 0.4848 - precision: 0.8333 - recall: 0.3537 - val_loss: 1.2530 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.3684\n",
            "Epoch 99/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2200 - accuracy: 0.4242 - precision: 0.8542 - recall: 0.3974 - val_loss: 1.3738 - val_accuracy: 0.2353 - val_precision: 0.6471 - val_recall: 0.3143\n",
            "Epoch 100/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.2797 - accuracy: 0.4394 - precision: 0.4375 - recall: 0.2049 - val_loss: 1.2498 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.3684\n",
            "Epoch 101/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.2074 - accuracy: 0.3939 - precision: 0.8854 - recall: 0.3721 - val_loss: 1.0685 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.3784\n",
            "Epoch 102/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.1733 - accuracy: 0.4394 - precision: 0.8854 - recall: 0.4144 - val_loss: 1.0597 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 103/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.2854 - accuracy: 0.3788 - precision: 0.6042 - recall: 0.2925 - val_loss: 1.0859 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.4194\n",
            "Epoch 104/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.3050 - accuracy: 0.3788 - precision: 0.7188 - recall: 0.3933 - val_loss: 1.0511 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.4516\n",
            "Epoch 105/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.2019 - accuracy: 0.4242 - precision: 0.7500 - recall: 0.3992 - val_loss: 1.0781 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 106/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.1581 - accuracy: 0.4697 - precision: 0.8333 - recall: 0.4663 - val_loss: 1.0984 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 107/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.1541 - accuracy: 0.5303 - precision: 0.8438 - recall: 0.4306 - val_loss: 1.0932 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 108/500\n",
            "3/3 [==============================] - 0s 17ms/step - loss: 1.1510 - accuracy: 0.5455 - precision: 0.8229 - recall: 0.4794 - val_loss: 1.0801 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4375\n",
            "Epoch 109/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.1485 - accuracy: 0.5303 - precision: 0.6667 - recall: 0.3714 - val_loss: 1.0855 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 110/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.1456 - accuracy: 0.5303 - precision: 0.8646 - recall: 0.3945 - val_loss: 1.0839 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.3784\n",
            "Epoch 111/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.1461 - accuracy: 0.5000 - precision: 0.7292 - recall: 0.3275 - val_loss: 1.0298 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 112/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.1622 - accuracy: 0.4697 - precision: 0.8333 - recall: 0.3665 - val_loss: 0.9965 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4516\n",
            "Epoch 113/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.1739 - accuracy: 0.4242 - precision: 0.6354 - recall: 0.3177 - val_loss: 0.9981 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 114/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.1391 - accuracy: 0.4697 - precision: 0.7083 - recall: 0.3347 - val_loss: 1.1150 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3784\n",
            "Epoch 115/500\n",
            "3/3 [==============================] - 0s 16ms/step - loss: 1.1755 - accuracy: 0.3939 - precision: 0.7396 - recall: 0.3454 - val_loss: 1.1942 - val_accuracy: 0.5294 - val_precision: 0.7647 - val_recall: 0.3514\n",
            "Epoch 116/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.2046 - accuracy: 0.3485 - precision: 0.8646 - recall: 0.3489 - val_loss: 1.1828 - val_accuracy: 0.5294 - val_precision: 0.7647 - val_recall: 0.3514\n",
            "Epoch 117/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.1889 - accuracy: 0.3788 - precision: 0.8646 - recall: 0.4146 - val_loss: 1.1697 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 118/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.1816 - accuracy: 0.3485 - precision: 0.8646 - recall: 0.4192 - val_loss: 1.1717 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.3947\n",
            "Epoch 119/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.1715 - accuracy: 0.3485 - precision: 0.5625 - recall: 0.2666 - val_loss: 1.1681 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 120/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.1681 - accuracy: 0.4394 - precision: 0.8854 - recall: 0.4265 - val_loss: 1.1747 - val_accuracy: 0.7059 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 121/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.1787 - accuracy: 0.4848 - precision: 0.8958 - recall: 0.4370 - val_loss: 1.1756 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 122/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.2021 - accuracy: 0.4242 - precision: 0.8646 - recall: 0.4236 - val_loss: 1.1296 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 123/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.2268 - accuracy: 0.4545 - precision: 0.6042 - recall: 0.3037 - val_loss: 1.1077 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 124/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.2143 - accuracy: 0.4394 - precision: 0.7917 - recall: 0.3556 - val_loss: 1.1114 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4545\n",
            "Epoch 125/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.1596 - accuracy: 0.4848 - precision: 0.5312 - recall: 0.2574 - val_loss: 1.1605 - val_accuracy: 0.7059 - val_precision: 0.8824 - val_recall: 0.4545\n",
            "Epoch 126/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 1.1348 - accuracy: 0.5455 - precision: 0.7083 - recall: 0.3590 - val_loss: 1.2053 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4545\n",
            "Epoch 127/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 1.1429 - accuracy: 0.5758 - precision: 0.8333 - recall: 0.4833 - val_loss: 1.2480 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 128/500\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.1596 - accuracy: 0.5152 - precision: 0.8542 - recall: 0.4288 - val_loss: 1.2870 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 129/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.1713 - accuracy: 0.4848 - precision: 0.8438 - recall: 0.4187 - val_loss: 1.2437 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 130/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1402 - accuracy: 0.5152 - precision: 0.5625 - recall: 0.2749 - val_loss: 1.1324 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3590\n",
            "Epoch 131/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1171 - accuracy: 0.4697 - precision: 0.8750 - recall: 0.3833 - val_loss: 1.0682 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.3846\n",
            "Epoch 132/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.1820 - accuracy: 0.4242 - precision: 0.6562 - recall: 0.2923 - val_loss: 1.0674 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.3902\n",
            "Epoch 133/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.2047 - accuracy: 0.4091 - precision: 0.6875 - recall: 0.2956 - val_loss: 1.0943 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4054\n",
            "Epoch 134/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.1106 - accuracy: 0.5303 - precision: 0.8750 - recall: 0.4074 - val_loss: 1.3366 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 135/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.2148 - accuracy: 0.3939 - precision: 0.6146 - recall: 0.3132 - val_loss: 1.4937 - val_accuracy: 0.2941 - val_precision: 0.6471 - val_recall: 0.3793\n",
            "Epoch 136/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.2504 - accuracy: 0.3485 - precision: 0.5729 - recall: 0.3251 - val_loss: 1.2661 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 137/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1257 - accuracy: 0.5303 - precision: 0.5625 - recall: 0.2729 - val_loss: 1.0976 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 138/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 1.1192 - accuracy: 0.4394 - precision: 0.7188 - recall: 0.3157 - val_loss: 1.0638 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 139/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 1.1529 - accuracy: 0.4545 - precision: 0.8958 - recall: 0.3974 - val_loss: 1.0912 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 140/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.1171 - accuracy: 0.5000 - precision: 0.8854 - recall: 0.4033 - val_loss: 1.1771 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.3846\n",
            "Epoch 141/500\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 1.1492 - accuracy: 0.4848 - precision: 0.5625 - recall: 0.2520 - val_loss: 1.2408 - val_accuracy: 0.4706 - val_precision: 0.8824 - val_recall: 0.3846\n",
            "Epoch 142/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.1384 - accuracy: 0.5152 - precision: 0.7188 - recall: 0.3392 - val_loss: 1.1398 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 143/500\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 1.1192 - accuracy: 0.5455 - precision: 0.8958 - recall: 0.3765 - val_loss: 1.0674 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 144/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.1475 - accuracy: 0.5000 - precision: 0.8958 - recall: 0.3464 - val_loss: 1.0215 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.3810\n",
            "Epoch 145/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.1930 - accuracy: 0.4545 - precision: 0.8438 - recall: 0.3365 - val_loss: 0.9990 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.3810\n",
            "Epoch 146/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.1951 - accuracy: 0.4545 - precision: 0.8542 - recall: 0.3394 - val_loss: 0.9928 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.3810\n",
            "Epoch 147/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.1506 - accuracy: 0.4697 - precision: 0.8438 - recall: 0.3427 - val_loss: 1.0334 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.3750\n",
            "Epoch 148/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.1288 - accuracy: 0.4697 - precision: 0.8542 - recall: 0.4078 - val_loss: 1.1653 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.3784\n",
            "Epoch 149/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.1560 - accuracy: 0.3333 - precision: 0.8958 - recall: 0.4352 - val_loss: 1.2419 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.3784\n",
            "Epoch 150/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.1822 - accuracy: 0.3333 - precision: 0.8854 - recall: 0.3971 - val_loss: 1.1566 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.3784\n",
            "Epoch 151/500\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 1.1440 - accuracy: 0.3636 - precision: 0.9062 - recall: 0.4302 - val_loss: 1.0339 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 152/500\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 1.1528 - accuracy: 0.4848 - precision: 0.6875 - recall: 0.3233 - val_loss: 1.0051 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 153/500\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 1.1531 - accuracy: 0.4848 - precision: 0.5208 - recall: 0.2436 - val_loss: 1.0661 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 154/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.1218 - accuracy: 0.5000 - precision: 0.8854 - recall: 0.4208 - val_loss: 1.1994 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 155/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.1214 - accuracy: 0.5000 - precision: 0.8854 - recall: 0.4344 - val_loss: 1.1414 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 156/500\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 1.0990 - accuracy: 0.5606 - precision: 0.7396 - recall: 0.3473 - val_loss: 1.0293 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 157/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.1316 - accuracy: 0.4697 - precision: 0.5312 - recall: 0.2281 - val_loss: 1.0110 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 158/500\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 1.1304 - accuracy: 0.4545 - precision: 0.6979 - recall: 0.3428 - val_loss: 1.0616 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 159/500\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 1.0997 - accuracy: 0.5455 - precision: 0.7292 - recall: 0.3424 - val_loss: 1.1864 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 160/500\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 1.1350 - accuracy: 0.5000 - precision: 0.8646 - recall: 0.4242 - val_loss: 1.1926 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3714\n",
            "Epoch 161/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.1411 - accuracy: 0.4848 - precision: 0.6875 - recall: 0.3438 - val_loss: 1.1193 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 162/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.1033 - accuracy: 0.5455 - precision: 0.8854 - recall: 0.4801 - val_loss: 1.0104 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 163/500\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 1.0954 - accuracy: 0.4697 - precision: 0.8542 - recall: 0.4010 - val_loss: 0.9591 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4571\n",
            "Epoch 164/500\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 1.1244 - accuracy: 0.4394 - precision: 0.8333 - recall: 0.3510 - val_loss: 0.9408 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 165/500\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 1.1524 - accuracy: 0.4242 - precision: 0.6562 - recall: 0.2813 - val_loss: 0.9425 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4054\n",
            "Epoch 166/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 1.0959 - accuracy: 0.4545 - precision: 0.8854 - recall: 0.4190 - val_loss: 1.0834 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 167/500\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 1.1428 - accuracy: 0.4242 - precision: 0.8750 - recall: 0.4254 - val_loss: 1.2540 - val_accuracy: 0.4118 - val_precision: 0.7059 - val_recall: 0.3529\n",
            "Epoch 168/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.2341 - accuracy: 0.3333 - precision: 0.6354 - recall: 0.3106 - val_loss: 1.1993 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 169/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 1.1835 - accuracy: 0.4242 - precision: 0.8542 - recall: 0.4192 - val_loss: 1.0628 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 170/500\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 1.1148 - accuracy: 0.5000 - precision: 0.8854 - recall: 0.4344 - val_loss: 1.0297 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 171/500\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 1.1084 - accuracy: 0.5000 - precision: 0.8958 - recall: 0.4392 - val_loss: 0.9973 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 172/500\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 1.1111 - accuracy: 0.5152 - precision: 0.8854 - recall: 0.4303 - val_loss: 0.9775 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 173/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.1212 - accuracy: 0.5000 - precision: 0.8646 - recall: 0.4147 - val_loss: 0.9497 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 174/500\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 1.1368 - accuracy: 0.5152 - precision: 0.5104 - recall: 0.2438 - val_loss: 0.9492 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 175/500\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 1.1192 - accuracy: 0.5000 - precision: 0.8750 - recall: 0.4216 - val_loss: 1.0112 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 176/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.1030 - accuracy: 0.4394 - precision: 0.8958 - recall: 0.4374 - val_loss: 1.0128 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 177/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.0888 - accuracy: 0.4545 - precision: 0.8958 - recall: 0.4371 - val_loss: 0.9687 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 178/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.0806 - accuracy: 0.5152 - precision: 0.8958 - recall: 0.4319 - val_loss: 0.9374 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 179/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.0875 - accuracy: 0.5000 - precision: 0.8958 - recall: 0.4275 - val_loss: 0.9511 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 180/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 1.0846 - accuracy: 0.5152 - precision: 0.8958 - recall: 0.3980 - val_loss: 0.9968 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 181/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.1066 - accuracy: 0.4545 - precision: 0.8958 - recall: 0.4355 - val_loss: 1.0745 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 182/500\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 1.1336 - accuracy: 0.4091 - precision: 0.8854 - recall: 0.4302 - val_loss: 1.1658 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 183/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.1838 - accuracy: 0.3333 - precision: 0.5521 - recall: 0.2677 - val_loss: 1.1940 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3824\n",
            "Epoch 184/500\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 1.1554 - accuracy: 0.3636 - precision: 0.8646 - recall: 0.4282 - val_loss: 1.0729 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4054\n",
            "Epoch 185/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.0952 - accuracy: 0.4394 - precision: 0.9062 - recall: 0.4381 - val_loss: 1.0023 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 186/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.0886 - accuracy: 0.5152 - precision: 0.9062 - recall: 0.3809 - val_loss: 1.0171 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 187/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 1.0876 - accuracy: 0.5606 - precision: 0.8854 - recall: 0.3672 - val_loss: 1.0148 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 188/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.0973 - accuracy: 0.5606 - precision: 0.8854 - recall: 0.3689 - val_loss: 1.0100 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 189/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.1026 - accuracy: 0.5152 - precision: 0.8646 - recall: 0.3584 - val_loss: 0.9942 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 190/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.1056 - accuracy: 0.4848 - precision: 0.7188 - recall: 0.2991 - val_loss: 1.0001 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 191/500\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 1.0693 - accuracy: 0.5152 - precision: 0.7396 - recall: 0.3311 - val_loss: 1.0872 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.3846\n",
            "Epoch 192/500\n",
            "3/3 [==============================] - 0s 88ms/step - loss: 1.0863 - accuracy: 0.4848 - precision: 0.5521 - recall: 0.2635 - val_loss: 1.2016 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 193/500\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 1.1008 - accuracy: 0.4848 - precision: 0.8542 - recall: 0.4292 - val_loss: 1.1216 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 194/500\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 1.0814 - accuracy: 0.5909 - precision: 0.7292 - recall: 0.3525 - val_loss: 1.0792 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 195/500\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 1.0852 - accuracy: 0.5909 - precision: 0.8646 - recall: 0.4151 - val_loss: 1.1164 - val_accuracy: 0.7059 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 196/500\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 1.0935 - accuracy: 0.5909 - precision: 0.8646 - recall: 0.4167 - val_loss: 1.1522 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.3889\n",
            "Epoch 197/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.0760 - accuracy: 0.5606 - precision: 0.8854 - recall: 0.3911 - val_loss: 1.0789 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4054\n",
            "Epoch 198/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 1.0593 - accuracy: 0.5606 - precision: 0.8646 - recall: 0.4165 - val_loss: 1.0411 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 199/500\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 1.0601 - accuracy: 0.5606 - precision: 0.7292 - recall: 0.3190 - val_loss: 1.0299 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 200/500\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 1.0575 - accuracy: 0.5606 - precision: 0.7396 - recall: 0.3622 - val_loss: 1.0155 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 201/500\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 1.0599 - accuracy: 0.5455 - precision: 0.8854 - recall: 0.3841 - val_loss: 0.9834 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 202/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.0548 - accuracy: 0.5606 - precision: 0.7604 - recall: 0.3337 - val_loss: 0.9853 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 203/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0486 - accuracy: 0.5455 - precision: 0.9062 - recall: 0.3845 - val_loss: 0.9860 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 204/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0481 - accuracy: 0.5606 - precision: 0.7500 - recall: 0.3355 - val_loss: 0.9899 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 205/500\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 1.0633 - accuracy: 0.5606 - precision: 0.8854 - recall: 0.4189 - val_loss: 1.1385 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 206/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 1.1115 - accuracy: 0.5303 - precision: 0.8750 - recall: 0.4276 - val_loss: 1.0853 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 207/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.0952 - accuracy: 0.5303 - precision: 0.8750 - recall: 0.4336 - val_loss: 0.9406 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 208/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 1.0642 - accuracy: 0.5152 - precision: 0.8958 - recall: 0.4082 - val_loss: 0.8908 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 209/500\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 1.0721 - accuracy: 0.5303 - precision: 0.8854 - recall: 0.4303 - val_loss: 0.9305 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 210/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 1.0631 - accuracy: 0.5152 - precision: 0.8854 - recall: 0.4406 - val_loss: 0.9440 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 211/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.0542 - accuracy: 0.5000 - precision: 0.8854 - recall: 0.4381 - val_loss: 0.9548 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 212/500\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 1.0508 - accuracy: 0.5152 - precision: 0.8958 - recall: 0.4458 - val_loss: 1.0047 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 213/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 1.0539 - accuracy: 0.5455 - precision: 0.5729 - recall: 0.2756 - val_loss: 0.9525 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 214/500\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 1.0218 - accuracy: 0.5455 - precision: 0.8958 - recall: 0.3890 - val_loss: 0.8968 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 215/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 1.0504 - accuracy: 0.5303 - precision: 0.8854 - recall: 0.3638 - val_loss: 0.8857 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 216/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 1.0836 - accuracy: 0.5000 - precision: 0.8750 - recall: 0.3523 - val_loss: 0.8864 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 217/500\n",
            "3/3 [==============================] - 0s 92ms/step - loss: 1.0292 - accuracy: 0.5000 - precision: 0.8958 - recall: 0.3869 - val_loss: 1.0237 - val_accuracy: 0.5294 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 218/500\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 1.0629 - accuracy: 0.5000 - precision: 0.8750 - recall: 0.4333 - val_loss: 1.2135 - val_accuracy: 0.2941 - val_precision: 0.7059 - val_recall: 0.3529\n",
            "Epoch 219/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.1632 - accuracy: 0.4091 - precision: 0.6771 - recall: 0.3364 - val_loss: 1.2058 - val_accuracy: 0.3529 - val_precision: 0.7059 - val_recall: 0.3636\n",
            "Epoch 220/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 1.1518 - accuracy: 0.4545 - precision: 0.8333 - recall: 0.4167 - val_loss: 1.0807 - val_accuracy: 0.4118 - val_precision: 0.7647 - val_recall: 0.3939\n",
            "Epoch 221/500\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 1.1003 - accuracy: 0.3636 - precision: 0.8750 - recall: 0.4375 - val_loss: 0.9657 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4375\n",
            "Epoch 222/500\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 1.1156 - accuracy: 0.4394 - precision: 0.6875 - recall: 0.3397 - val_loss: 0.9141 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 223/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.1020 - accuracy: 0.4697 - precision: 0.6875 - recall: 0.3401 - val_loss: 0.9633 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 224/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.0375 - accuracy: 0.4697 - precision: 0.8854 - recall: 0.4384 - val_loss: 1.1923 - val_accuracy: 0.4706 - val_precision: 0.7647 - val_recall: 0.3939\n",
            "Epoch 225/500\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 1.1435 - accuracy: 0.4242 - precision: 0.8021 - recall: 0.4045 - val_loss: 1.3243 - val_accuracy: 0.1765 - val_precision: 0.7647 - val_recall: 0.3714\n",
            "Epoch 226/500\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 1.2013 - accuracy: 0.4091 - precision: 0.7604 - recall: 0.3761 - val_loss: 1.1841 - val_accuracy: 0.4706 - val_precision: 0.7647 - val_recall: 0.4062\n",
            "Epoch 227/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 1.1032 - accuracy: 0.4545 - precision: 0.8542 - recall: 0.4264 - val_loss: 0.9840 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 228/500\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 1.0316 - accuracy: 0.5000 - precision: 0.7188 - recall: 0.3551 - val_loss: 0.9270 - val_accuracy: 0.7059 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 229/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 1.0499 - accuracy: 0.5152 - precision: 0.7083 - recall: 0.3401 - val_loss: 0.9577 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 230/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.0319 - accuracy: 0.5152 - precision: 0.9167 - recall: 0.4333 - val_loss: 1.0768 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4571\n",
            "Epoch 231/500\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 1.0380 - accuracy: 0.5606 - precision: 0.8958 - recall: 0.3841 - val_loss: 1.0368 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4706\n",
            "Epoch 232/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.0084 - accuracy: 0.5758 - precision: 0.8854 - recall: 0.4427 - val_loss: 0.9809 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 233/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 1.0703 - accuracy: 0.4848 - precision: 0.6979 - recall: 0.3429 - val_loss: 0.9919 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 234/500\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 1.0364 - accuracy: 0.5303 - precision: 0.8750 - recall: 0.4312 - val_loss: 1.0834 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 235/500\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 1.0519 - accuracy: 0.5758 - precision: 0.8854 - recall: 0.4411 - val_loss: 1.1143 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4375\n",
            "Epoch 236/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.0684 - accuracy: 0.5758 - precision: 0.8750 - recall: 0.4508 - val_loss: 1.0644 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 237/500\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 1.0691 - accuracy: 0.5606 - precision: 0.7083 - recall: 0.3641 - val_loss: 1.0466 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 238/500\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 1.0589 - accuracy: 0.5606 - precision: 0.8646 - recall: 0.4921 - val_loss: 1.0523 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 239/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 1.0566 - accuracy: 0.5455 - precision: 0.8750 - recall: 0.4415 - val_loss: 1.0015 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 240/500\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 1.0438 - accuracy: 0.5606 - precision: 0.7292 - recall: 0.3603 - val_loss: 0.9730 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 241/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.0308 - accuracy: 0.5455 - precision: 0.7188 - recall: 0.3594 - val_loss: 0.9668 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 242/500\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 1.0132 - accuracy: 0.5455 - precision: 0.8750 - recall: 0.4063 - val_loss: 0.9570 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4848\n",
            "Epoch 243/500\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 1.0109 - accuracy: 0.5455 - precision: 0.9062 - recall: 0.4422 - val_loss: 0.9728 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 244/500\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 1.0084 - accuracy: 0.5758 - precision: 0.7500 - recall: 0.3617 - val_loss: 1.0329 - val_accuracy: 0.7059 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 245/500\n",
            "3/3 [==============================] - 0s 75ms/step - loss: 1.0424 - accuracy: 0.5909 - precision: 0.5521 - recall: 0.2581 - val_loss: 1.0711 - val_accuracy: 0.7059 - val_precision: 0.8824 - val_recall: 0.4054\n",
            "Epoch 246/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 1.0526 - accuracy: 0.5758 - precision: 0.7396 - recall: 0.3426 - val_loss: 0.9776 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4706\n",
            "Epoch 247/500\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 1.0058 - accuracy: 0.5909 - precision: 0.9062 - recall: 0.3924 - val_loss: 0.9587 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 248/500\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 1.0000 - accuracy: 0.5606 - precision: 0.9062 - recall: 0.4268 - val_loss: 0.9724 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 249/500\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.9966 - accuracy: 0.5000 - precision: 0.9062 - recall: 0.4353 - val_loss: 1.0630 - val_accuracy: 0.5882 - val_precision: 0.8235 - val_recall: 0.4118\n",
            "Epoch 250/500\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 1.0438 - accuracy: 0.5152 - precision: 0.8750 - recall: 0.4022 - val_loss: 1.1085 - val_accuracy: 0.4118 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 251/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.0521 - accuracy: 0.4848 - precision: 0.8750 - recall: 0.4378 - val_loss: 1.0108 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 252/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.0308 - accuracy: 0.4545 - precision: 0.7188 - recall: 0.3530 - val_loss: 0.9332 - val_accuracy: 0.6471 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 253/500\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 1.1084 - accuracy: 0.4545 - precision: 0.7083 - recall: 0.3481 - val_loss: 0.9213 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 254/500\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 1.0805 - accuracy: 0.4848 - precision: 0.7083 - recall: 0.3481 - val_loss: 0.9867 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 255/500\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 1.0016 - accuracy: 0.5303 - precision: 0.7396 - recall: 0.3633 - val_loss: 1.3136 - val_accuracy: 0.1765 - val_precision: 0.7059 - val_recall: 0.3529\n",
            "Epoch 256/500\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 1.2291 - accuracy: 0.3333 - precision: 0.5938 - recall: 0.2915 - val_loss: 1.3772 - val_accuracy: 0.1765 - val_precision: 0.7059 - val_recall: 0.3429\n",
            "Epoch 257/500\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 1.2291 - accuracy: 0.3485 - precision: 0.7812 - recall: 0.3496 - val_loss: 1.0310 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4595\n",
            "Epoch 258/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 1.0201 - accuracy: 0.5303 - precision: 0.7083 - recall: 0.3345 - val_loss: 0.8895 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 259/500\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 1.0362 - accuracy: 0.5000 - precision: 0.8854 - recall: 0.4782 - val_loss: 0.8897 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4571\n",
            "Epoch 260/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 1.0460 - accuracy: 0.4848 - precision: 0.8750 - recall: 0.3999 - val_loss: 0.9193 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 261/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 1.0275 - accuracy: 0.5606 - precision: 0.8958 - recall: 0.4335 - val_loss: 0.9818 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4545\n",
            "Epoch 262/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 1.0384 - accuracy: 0.5758 - precision: 0.7396 - recall: 0.3637 - val_loss: 1.0698 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 263/500\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 1.0891 - accuracy: 0.5000 - precision: 0.7188 - recall: 0.3551 - val_loss: 1.0845 - val_accuracy: 0.4118 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 264/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.0755 - accuracy: 0.5303 - precision: 0.8750 - recall: 0.4018 - val_loss: 1.0085 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 265/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 1.0174 - accuracy: 0.5606 - precision: 0.9167 - recall: 0.3945 - val_loss: 0.9540 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4571\n",
            "Epoch 266/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0003 - accuracy: 0.5606 - precision: 0.9375 - recall: 0.4312 - val_loss: 0.9114 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 267/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 1.0088 - accuracy: 0.5606 - precision: 0.7708 - recall: 0.3693 - val_loss: 0.8939 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 268/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.9987 - accuracy: 0.5303 - precision: 0.7292 - recall: 0.3352 - val_loss: 0.9328 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 269/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 1.0131 - accuracy: 0.5758 - precision: 0.7292 - recall: 0.3886 - val_loss: 1.0267 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.4242\n",
            "Epoch 270/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.0654 - accuracy: 0.5152 - precision: 0.8750 - recall: 0.4375 - val_loss: 0.9988 - val_accuracy: 0.4706 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 271/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 1.0343 - accuracy: 0.5303 - precision: 0.8854 - recall: 0.4386 - val_loss: 0.8972 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 272/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.9954 - accuracy: 0.5758 - precision: 0.9062 - recall: 0.3789 - val_loss: 0.8283 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 273/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 1.0279 - accuracy: 0.4848 - precision: 0.8958 - recall: 0.3816 - val_loss: 0.8292 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 274/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 1.0826 - accuracy: 0.4697 - precision: 0.8750 - recall: 0.3676 - val_loss: 0.8281 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 275/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 1.0139 - accuracy: 0.5303 - precision: 0.8854 - recall: 0.4157 - val_loss: 0.8835 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 276/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 1.0014 - accuracy: 0.5909 - precision: 0.8958 - recall: 0.4356 - val_loss: 0.9753 - val_accuracy: 0.4118 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 277/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 1.0500 - accuracy: 0.5303 - precision: 0.8750 - recall: 0.4313 - val_loss: 0.9898 - val_accuracy: 0.4706 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 278/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 1.0529 - accuracy: 0.5152 - precision: 0.7188 - recall: 0.3553 - val_loss: 0.9283 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 279/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 1.0067 - accuracy: 0.5455 - precision: 0.8854 - recall: 0.3992 - val_loss: 0.8587 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 280/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.9713 - accuracy: 0.5758 - precision: 0.9271 - recall: 0.3827 - val_loss: 0.8453 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 281/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.9767 - accuracy: 0.5455 - precision: 0.7500 - recall: 0.3314 - val_loss: 0.8628 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 282/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.9769 - accuracy: 0.5455 - precision: 0.9062 - recall: 0.4249 - val_loss: 0.9061 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 283/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.9772 - accuracy: 0.4697 - precision: 0.7604 - recall: 0.3528 - val_loss: 0.9113 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 284/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.9848 - accuracy: 0.4697 - precision: 0.7500 - recall: 0.3747 - val_loss: 0.9206 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 285/500\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.9868 - accuracy: 0.4697 - precision: 0.7604 - recall: 0.3547 - val_loss: 0.9739 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 286/500\n",
            "3/3 [==============================] - 0s 95ms/step - loss: 0.9938 - accuracy: 0.4848 - precision: 0.9062 - recall: 0.3973 - val_loss: 0.9908 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4054\n",
            "Epoch 287/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.9825 - accuracy: 0.5000 - precision: 0.8958 - recall: 0.4257 - val_loss: 0.9613 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 288/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.9704 - accuracy: 0.5152 - precision: 0.7396 - recall: 0.3530 - val_loss: 0.9254 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 289/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9690 - accuracy: 0.5455 - precision: 0.8854 - recall: 0.4773 - val_loss: 0.9275 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 290/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.9655 - accuracy: 0.5909 - precision: 0.7708 - recall: 0.3843 - val_loss: 0.9564 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 291/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.9541 - accuracy: 0.6212 - precision: 0.9479 - recall: 0.4137 - val_loss: 0.9722 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 292/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.9530 - accuracy: 0.5606 - precision: 0.9167 - recall: 0.4042 - val_loss: 0.9105 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 293/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.9650 - accuracy: 0.5758 - precision: 0.8750 - recall: 0.4166 - val_loss: 0.8861 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 294/500\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.9813 - accuracy: 0.5455 - precision: 0.8750 - recall: 0.4254 - val_loss: 0.8649 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 295/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.9630 - accuracy: 0.5606 - precision: 0.8958 - recall: 0.4353 - val_loss: 0.8586 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 296/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.9554 - accuracy: 0.5758 - precision: 0.8958 - recall: 0.4373 - val_loss: 0.9086 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.4706\n",
            "Epoch 297/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.9677 - accuracy: 0.5606 - precision: 0.8854 - recall: 0.4332 - val_loss: 0.8513 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4706\n",
            "Epoch 298/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.9491 - accuracy: 0.5758 - precision: 0.7500 - recall: 0.3578 - val_loss: 0.8104 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 299/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.9455 - accuracy: 0.5758 - precision: 0.8958 - recall: 0.3924 - val_loss: 0.7980 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 300/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.9505 - accuracy: 0.5758 - precision: 0.9479 - recall: 0.4397 - val_loss: 0.7961 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 301/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.9820 - accuracy: 0.5606 - precision: 0.7917 - recall: 0.3797 - val_loss: 0.7948 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 302/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0206 - accuracy: 0.5000 - precision: 0.7812 - recall: 0.3437 - val_loss: 0.8198 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 303/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.9539 - accuracy: 0.5606 - precision: 0.7812 - recall: 0.3544 - val_loss: 0.8987 - val_accuracy: 0.4706 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 304/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.9388 - accuracy: 0.5758 - precision: 0.8958 - recall: 0.4322 - val_loss: 0.8928 - val_accuracy: 0.4706 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 305/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.9733 - accuracy: 0.5455 - precision: 0.8958 - recall: 0.4314 - val_loss: 0.9368 - val_accuracy: 0.4706 - val_precision: 0.8824 - val_recall: 0.4054\n",
            "Epoch 306/500\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 1.0376 - accuracy: 0.5455 - precision: 0.8958 - recall: 0.3962 - val_loss: 0.9371 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4054\n",
            "Epoch 307/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 1.0345 - accuracy: 0.5152 - precision: 0.7396 - recall: 0.3510 - val_loss: 0.9235 - val_accuracy: 0.4118 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 308/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.9904 - accuracy: 0.5606 - precision: 0.8750 - recall: 0.4344 - val_loss: 1.1096 - val_accuracy: 0.3529 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 309/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 1.1059 - accuracy: 0.5152 - precision: 0.8125 - recall: 0.3888 - val_loss: 0.9969 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 310/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 1.0203 - accuracy: 0.5455 - precision: 0.8750 - recall: 0.4038 - val_loss: 0.8450 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 311/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.9824 - accuracy: 0.5455 - precision: 0.9062 - recall: 0.4395 - val_loss: 0.8592 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 312/500\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 1.1553 - accuracy: 0.4848 - precision: 0.5312 - recall: 0.2573 - val_loss: 0.8449 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 313/500\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 1.0372 - accuracy: 0.4848 - precision: 0.8750 - recall: 0.3960 - val_loss: 0.8553 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 314/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9642 - accuracy: 0.5606 - precision: 0.9062 - recall: 0.4531 - val_loss: 0.9098 - val_accuracy: 0.5294 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 315/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.9820 - accuracy: 0.5455 - precision: 0.7292 - recall: 0.3624 - val_loss: 0.8590 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4595\n",
            "Epoch 316/500\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.9481 - accuracy: 0.5455 - precision: 0.9062 - recall: 0.4019 - val_loss: 0.7935 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 317/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.9138 - accuracy: 0.5606 - precision: 0.9479 - recall: 0.3943 - val_loss: 0.7296 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 318/500\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.9334 - accuracy: 0.5758 - precision: 0.9062 - recall: 0.4879 - val_loss: 0.7281 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 319/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.9276 - accuracy: 0.5758 - precision: 0.9167 - recall: 0.4298 - val_loss: 0.7617 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 320/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.9291 - accuracy: 0.5455 - precision: 0.9479 - recall: 0.3991 - val_loss: 0.7993 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 321/500\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.9405 - accuracy: 0.5606 - precision: 0.9479 - recall: 0.3742 - val_loss: 0.7652 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 322/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.9414 - accuracy: 0.5152 - precision: 0.9167 - recall: 0.4353 - val_loss: 0.7840 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4722\n",
            "Epoch 323/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.9730 - accuracy: 0.5000 - precision: 0.9062 - recall: 0.4487 - val_loss: 0.8169 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4706\n",
            "Epoch 324/500\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.9989 - accuracy: 0.4848 - precision: 0.8854 - recall: 0.4471 - val_loss: 0.8677 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 325/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0192 - accuracy: 0.4394 - precision: 0.7188 - recall: 0.3872 - val_loss: 0.8194 - val_accuracy: 0.7059 - val_precision: 0.8824 - val_recall: 0.4545\n",
            "Epoch 326/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.9538 - accuracy: 0.5909 - precision: 0.8958 - recall: 0.4392 - val_loss: 0.7113 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 327/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.9307 - accuracy: 0.5606 - precision: 0.7812 - recall: 0.3548 - val_loss: 0.6932 - val_accuracy: 0.5294 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 328/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 1.0296 - accuracy: 0.5303 - precision: 0.9062 - recall: 0.3589 - val_loss: 0.7179 - val_accuracy: 0.5294 - val_precision: 1.0000 - val_recall: 0.3953\n",
            "Epoch 329/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 1.0751 - accuracy: 0.4848 - precision: 0.9062 - recall: 0.4033 - val_loss: 0.6998 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 330/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.9456 - accuracy: 0.5606 - precision: 0.9375 - recall: 0.4803 - val_loss: 0.7757 - val_accuracy: 0.5294 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 331/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.9497 - accuracy: 0.5606 - precision: 0.9271 - recall: 0.4016 - val_loss: 0.8384 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 332/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.9369 - accuracy: 0.5606 - precision: 0.9167 - recall: 0.4354 - val_loss: 0.7529 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4595\n",
            "Epoch 333/500\n",
            "3/3 [==============================] - 0s 39ms/step - loss: 0.8943 - accuracy: 0.5909 - precision: 0.8958 - recall: 0.4390 - val_loss: 0.7439 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4571\n",
            "Epoch 334/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.9542 - accuracy: 0.5909 - precision: 0.9062 - recall: 0.4998 - val_loss: 0.7729 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.4571\n",
            "Epoch 335/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.9861 - accuracy: 0.5455 - precision: 0.8958 - recall: 0.4416 - val_loss: 0.7322 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 336/500\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.9292 - accuracy: 0.5909 - precision: 0.7500 - recall: 0.3942 - val_loss: 0.7227 - val_accuracy: 0.5294 - val_precision: 1.0000 - val_recall: 0.4595\n",
            "Epoch 337/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.8944 - accuracy: 0.5758 - precision: 0.7708 - recall: 0.3468 - val_loss: 0.8155 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 338/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.9322 - accuracy: 0.5909 - precision: 0.9167 - recall: 0.4242 - val_loss: 0.7514 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 339/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.8929 - accuracy: 0.6061 - precision: 0.9375 - recall: 0.4070 - val_loss: 0.7275 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 340/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.8741 - accuracy: 0.6364 - precision: 0.9583 - recall: 0.3952 - val_loss: 0.8703 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 341/500\n",
            "3/3 [==============================] - 0s 29ms/step - loss: 0.9976 - accuracy: 0.5152 - precision: 0.7396 - recall: 0.3358 - val_loss: 1.1377 - val_accuracy: 0.2353 - val_precision: 0.8235 - val_recall: 0.4000\n",
            "Epoch 342/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.0762 - accuracy: 0.4697 - precision: 0.8646 - recall: 0.3635 - val_loss: 0.8745 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 343/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.9091 - accuracy: 0.5909 - precision: 0.7812 - recall: 0.3749 - val_loss: 0.7773 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 344/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.8686 - accuracy: 0.6061 - precision: 0.8021 - recall: 0.4324 - val_loss: 0.7787 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.3953\n",
            "Epoch 345/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.8827 - accuracy: 0.6364 - precision: 0.9688 - recall: 0.4380 - val_loss: 0.8275 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 346/500\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.8981 - accuracy: 0.5909 - precision: 0.9375 - recall: 0.3982 - val_loss: 0.8958 - val_accuracy: 0.5882 - val_precision: 0.8824 - val_recall: 0.4054\n",
            "Epoch 347/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.9705 - accuracy: 0.5303 - precision: 0.7708 - recall: 0.3371 - val_loss: 0.8889 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 348/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.9231 - accuracy: 0.6212 - precision: 0.9479 - recall: 0.4027 - val_loss: 0.7537 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.3953\n",
            "Epoch 349/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.8525 - accuracy: 0.6364 - precision: 0.9375 - recall: 0.3673 - val_loss: 0.7790 - val_accuracy: 0.5294 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 350/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 1.0487 - accuracy: 0.4848 - precision: 0.9167 - recall: 0.3789 - val_loss: 0.7433 - val_accuracy: 0.5294 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 351/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.9305 - accuracy: 0.5758 - precision: 0.9479 - recall: 0.3904 - val_loss: 0.7633 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 352/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.8771 - accuracy: 0.6061 - precision: 0.9375 - recall: 0.3779 - val_loss: 0.8404 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 353/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.9143 - accuracy: 0.5758 - precision: 0.9375 - recall: 0.4094 - val_loss: 0.7257 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 354/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.8792 - accuracy: 0.6212 - precision: 0.7604 - recall: 0.3429 - val_loss: 0.7199 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 355/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.8899 - accuracy: 0.6212 - precision: 0.9167 - recall: 0.4259 - val_loss: 0.7104 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 356/500\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 0.8710 - accuracy: 0.6212 - precision: 0.9271 - recall: 0.3918 - val_loss: 0.7032 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 357/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.8499 - accuracy: 0.6212 - precision: 0.9688 - recall: 0.4923 - val_loss: 0.7141 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 358/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.8464 - accuracy: 0.6364 - precision: 0.9688 - recall: 0.4101 - val_loss: 0.7076 - val_accuracy: 0.5294 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 359/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.8414 - accuracy: 0.6212 - precision: 0.9688 - recall: 0.4437 - val_loss: 0.6892 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 360/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.8731 - accuracy: 0.6212 - precision: 0.9688 - recall: 0.3831 - val_loss: 0.6801 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 361/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.8541 - accuracy: 0.5909 - precision: 0.9583 - recall: 0.3743 - val_loss: 0.8001 - val_accuracy: 0.5294 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 362/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.9376 - accuracy: 0.5455 - precision: 0.9167 - recall: 0.3925 - val_loss: 0.9097 - val_accuracy: 0.4118 - val_precision: 0.8824 - val_recall: 0.4054\n",
            "Epoch 363/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.9236 - accuracy: 0.5909 - precision: 0.9271 - recall: 0.3732 - val_loss: 0.7109 - val_accuracy: 0.4706 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 364/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.8630 - accuracy: 0.5909 - precision: 0.9688 - recall: 0.3877 - val_loss: 0.7702 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.3902\n",
            "Epoch 365/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.9092 - accuracy: 0.5606 - precision: 0.9271 - recall: 0.3884 - val_loss: 0.7616 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 366/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.8626 - accuracy: 0.6515 - precision: 0.9271 - recall: 0.4216 - val_loss: 0.7758 - val_accuracy: 0.5294 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 367/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.8492 - accuracy: 0.6061 - precision: 0.9271 - recall: 0.3935 - val_loss: 0.8056 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 368/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.8469 - accuracy: 0.5909 - precision: 0.7917 - recall: 0.3709 - val_loss: 0.7746 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 369/500\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.8250 - accuracy: 0.6364 - precision: 0.9583 - recall: 0.4331 - val_loss: 0.7280 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.3953\n",
            "Epoch 370/500\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.8349 - accuracy: 0.6515 - precision: 0.9792 - recall: 0.4034 - val_loss: 0.7069 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 371/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.8695 - accuracy: 0.6061 - precision: 0.7604 - recall: 0.3217 - val_loss: 0.7035 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.3902\n",
            "Epoch 372/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.9514 - accuracy: 0.5758 - precision: 0.7500 - recall: 0.3356 - val_loss: 0.6845 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 373/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.9008 - accuracy: 0.6515 - precision: 0.8958 - recall: 0.3801 - val_loss: 0.7483 - val_accuracy: 0.7059 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 374/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 1.0157 - accuracy: 0.4697 - precision: 0.8854 - recall: 0.3878 - val_loss: 0.8033 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4412\n",
            "Epoch 375/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 1.0186 - accuracy: 0.4848 - precision: 0.8958 - recall: 0.3834 - val_loss: 0.6761 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 376/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.8855 - accuracy: 0.5758 - precision: 0.9479 - recall: 0.4034 - val_loss: 0.6670 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 377/500\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.8741 - accuracy: 0.6364 - precision: 0.9375 - recall: 0.3669 - val_loss: 0.6915 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.3864\n",
            "Epoch 378/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.9285 - accuracy: 0.6061 - precision: 0.9271 - recall: 0.3780 - val_loss: 0.6873 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.3636\n",
            "Epoch 379/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.8514 - accuracy: 0.6364 - precision: 0.9479 - recall: 0.3938 - val_loss: 0.6643 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.3902\n",
            "Epoch 380/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.8257 - accuracy: 0.6364 - precision: 0.8125 - recall: 0.3614 - val_loss: 0.6806 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 381/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.8155 - accuracy: 0.6212 - precision: 0.9792 - recall: 0.4054 - val_loss: 0.6965 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 382/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.8288 - accuracy: 0.6212 - precision: 0.9479 - recall: 0.3808 - val_loss: 0.7483 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 383/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.8670 - accuracy: 0.6212 - precision: 0.9375 - recall: 0.4056 - val_loss: 0.7359 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 384/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.8465 - accuracy: 0.6212 - precision: 0.9479 - recall: 0.4392 - val_loss: 0.7406 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 385/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.8192 - accuracy: 0.6061 - precision: 0.7812 - recall: 0.3533 - val_loss: 0.6909 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 386/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.7961 - accuracy: 0.6515 - precision: 0.9688 - recall: 0.4401 - val_loss: 0.6835 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 387/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.8325 - accuracy: 0.6364 - precision: 0.9167 - recall: 0.3817 - val_loss: 0.6738 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 388/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.7909 - accuracy: 0.6667 - precision: 0.9792 - recall: 0.4960 - val_loss: 0.7228 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 389/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.8492 - accuracy: 0.6364 - precision: 0.9479 - recall: 0.4409 - val_loss: 0.7005 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 390/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.8120 - accuracy: 0.6515 - precision: 0.9688 - recall: 0.4383 - val_loss: 0.5968 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.3953\n",
            "Epoch 391/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.8031 - accuracy: 0.6515 - precision: 0.9688 - recall: 0.4898 - val_loss: 0.5858 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.3953\n",
            "Epoch 392/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.8243 - accuracy: 0.6212 - precision: 0.8021 - recall: 0.4328 - val_loss: 0.5890 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.3864\n",
            "Epoch 393/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.8009 - accuracy: 0.6667 - precision: 0.9583 - recall: 0.4000 - val_loss: 0.6168 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 394/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.7834 - accuracy: 0.6818 - precision: 0.9583 - recall: 0.4338 - val_loss: 0.6379 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 395/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.8068 - accuracy: 0.6212 - precision: 0.8125 - recall: 0.3517 - val_loss: 0.6059 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 396/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.8137 - accuracy: 0.6212 - precision: 0.8125 - recall: 0.3888 - val_loss: 0.6029 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 397/500\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.7929 - accuracy: 0.6515 - precision: 0.9688 - recall: 0.4325 - val_loss: 0.6908 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.3864\n",
            "Epoch 398/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.8432 - accuracy: 0.6212 - precision: 0.9688 - recall: 0.3685 - val_loss: 0.6658 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.3778\n",
            "Epoch 399/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.8379 - accuracy: 0.6515 - precision: 0.9583 - recall: 0.3664 - val_loss: 0.6803 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 400/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.8116 - accuracy: 0.6515 - precision: 0.8125 - recall: 0.3519 - val_loss: 0.7095 - val_accuracy: 0.7059 - val_precision: 0.8824 - val_recall: 0.3947\n",
            "Epoch 401/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.8547 - accuracy: 0.5909 - precision: 0.9062 - recall: 0.4213 - val_loss: 1.0426 - val_accuracy: 0.4706 - val_precision: 0.7647 - val_recall: 0.3714\n",
            "Epoch 402/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 1.2505 - accuracy: 0.4091 - precision: 0.7812 - recall: 0.3809 - val_loss: 1.0873 - val_accuracy: 0.4706 - val_precision: 0.7647 - val_recall: 0.3611\n",
            "Epoch 403/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 1.2029 - accuracy: 0.4697 - precision: 0.8021 - recall: 0.3886 - val_loss: 0.8008 - val_accuracy: 0.6471 - val_precision: 0.8824 - val_recall: 0.4286\n",
            "Epoch 404/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.8599 - accuracy: 0.6212 - precision: 0.9062 - recall: 0.3991 - val_loss: 0.6657 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4595\n",
            "Epoch 405/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.7920 - accuracy: 0.6515 - precision: 0.9583 - recall: 0.4118 - val_loss: 0.6338 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 406/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.7991 - accuracy: 0.6515 - precision: 0.9688 - recall: 0.4420 - val_loss: 0.6110 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 407/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.7855 - accuracy: 0.6515 - precision: 0.9688 - recall: 0.4471 - val_loss: 0.5997 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 408/500\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.7770 - accuracy: 0.6667 - precision: 0.9792 - recall: 0.3926 - val_loss: 0.6241 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 409/500\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.8266 - accuracy: 0.6364 - precision: 0.9688 - recall: 0.4159 - val_loss: 0.6518 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 410/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8306 - accuracy: 0.6061 - precision: 0.9583 - recall: 0.4149 - val_loss: 0.5777 - val_accuracy: 0.8235 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 411/500\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.8168 - accuracy: 0.6212 - precision: 0.9167 - recall: 0.3764 - val_loss: 0.6236 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 412/500\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.9207 - accuracy: 0.5455 - precision: 0.8958 - recall: 0.4311 - val_loss: 0.6420 - val_accuracy: 0.8235 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 413/500\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.8978 - accuracy: 0.6061 - precision: 0.9479 - recall: 0.4367 - val_loss: 0.5754 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 414/500\n",
            "3/3 [==============================] - 0s 71ms/step - loss: 0.7716 - accuracy: 0.6970 - precision: 0.9583 - recall: 0.4317 - val_loss: 0.7610 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 415/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.9058 - accuracy: 0.6212 - precision: 0.7604 - recall: 0.3265 - val_loss: 0.6912 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 416/500\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.7650 - accuracy: 0.7576 - precision: 0.9479 - recall: 0.4330 - val_loss: 0.6568 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 417/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.8881 - accuracy: 0.6515 - precision: 0.9271 - recall: 0.3991 - val_loss: 0.7659 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 418/500\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 1.0051 - accuracy: 0.5909 - precision: 0.8958 - recall: 0.4353 - val_loss: 0.7718 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 419/500\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.9194 - accuracy: 0.6212 - precision: 0.9062 - recall: 0.3989 - val_loss: 0.7906 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4706\n",
            "Epoch 420/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.8749 - accuracy: 0.5909 - precision: 0.7292 - recall: 0.3243 - val_loss: 0.9018 - val_accuracy: 0.4706 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 421/500\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.9247 - accuracy: 0.5152 - precision: 0.8542 - recall: 0.3820 - val_loss: 0.9750 - val_accuracy: 0.3529 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 422/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.9101 - accuracy: 0.5303 - precision: 0.8958 - recall: 0.4221 - val_loss: 0.9634 - val_accuracy: 0.2941 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 423/500\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.8659 - accuracy: 0.5000 - precision: 0.9583 - recall: 0.4098 - val_loss: 0.9369 - val_accuracy: 0.3529 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 424/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.8291 - accuracy: 0.5606 - precision: 0.9479 - recall: 0.4026 - val_loss: 0.9353 - val_accuracy: 0.5294 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 425/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.8261 - accuracy: 0.6515 - precision: 0.9479 - recall: 0.4305 - val_loss: 0.9289 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 426/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.8119 - accuracy: 0.6667 - precision: 0.7812 - recall: 0.3459 - val_loss: 0.8363 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 427/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.7684 - accuracy: 0.6970 - precision: 0.9479 - recall: 0.4021 - val_loss: 0.7248 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 428/500\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.7560 - accuracy: 0.6970 - precision: 0.9583 - recall: 0.4004 - val_loss: 0.6840 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 429/500\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.7983 - accuracy: 0.6212 - precision: 0.7917 - recall: 0.3430 - val_loss: 0.6541 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 430/500\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.7684 - accuracy: 0.6818 - precision: 0.9688 - recall: 0.4919 - val_loss: 0.7640 - val_accuracy: 0.5294 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 431/500\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.8226 - accuracy: 0.6364 - precision: 0.7812 - recall: 0.3272 - val_loss: 0.7190 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.3953\n",
            "Epoch 432/500\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.7745 - accuracy: 0.6515 - precision: 0.9688 - recall: 0.4326 - val_loss: 0.6136 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 433/500\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.7737 - accuracy: 0.6364 - precision: 0.9688 - recall: 0.4291 - val_loss: 0.6021 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 434/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.7730 - accuracy: 0.6364 - precision: 0.9792 - recall: 0.4423 - val_loss: 0.5833 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 435/500\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.7552 - accuracy: 0.6818 - precision: 0.9896 - recall: 0.4100 - val_loss: 0.6107 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 436/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.7433 - accuracy: 0.6667 - precision: 0.9688 - recall: 0.4414 - val_loss: 0.6671 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 437/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.7443 - accuracy: 0.6970 - precision: 0.9688 - recall: 0.4045 - val_loss: 0.6876 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 438/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.7315 - accuracy: 0.6970 - precision: 0.9688 - recall: 0.4919 - val_loss: 0.7058 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.3864\n",
            "Epoch 439/500\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.7672 - accuracy: 0.6515 - precision: 0.9688 - recall: 0.3980 - val_loss: 0.6940 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.3778\n",
            "Epoch 440/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.7640 - accuracy: 0.6818 - precision: 0.9688 - recall: 0.4274 - val_loss: 0.6060 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 441/500\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.7316 - accuracy: 0.7424 - precision: 0.9792 - recall: 0.4355 - val_loss: 0.5694 - val_accuracy: 0.8824 - val_precision: 1.0000 - val_recall: 0.4595\n",
            "Epoch 442/500\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.7408 - accuracy: 0.6515 - precision: 0.9896 - recall: 0.3934 - val_loss: 0.6637 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 443/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.8570 - accuracy: 0.6364 - precision: 0.9271 - recall: 0.3983 - val_loss: 1.0377 - val_accuracy: 0.4706 - val_precision: 0.8235 - val_recall: 0.3784\n",
            "Epoch 444/500\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 1.0039 - accuracy: 0.5455 - precision: 0.9167 - recall: 0.4072 - val_loss: 0.7746 - val_accuracy: 0.5882 - val_precision: 0.9412 - val_recall: 0.3810\n",
            "Epoch 445/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.8082 - accuracy: 0.6212 - precision: 0.9479 - recall: 0.3838 - val_loss: 0.6230 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.3696\n",
            "Epoch 446/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.8353 - accuracy: 0.6818 - precision: 0.9583 - recall: 0.4151 - val_loss: 0.6739 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 447/500\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.8242 - accuracy: 0.6515 - precision: 0.9792 - recall: 0.3969 - val_loss: 0.6515 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 448/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.8196 - accuracy: 0.6212 - precision: 0.7708 - recall: 0.3482 - val_loss: 0.6695 - val_accuracy: 0.7059 - val_precision: 0.8824 - val_recall: 0.4167\n",
            "Epoch 449/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.8166 - accuracy: 0.6212 - precision: 0.7604 - recall: 0.3435 - val_loss: 0.5942 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 450/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.7009 - accuracy: 0.7273 - precision: 0.9792 - recall: 0.3944 - val_loss: 0.6924 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.3864\n",
            "Epoch 451/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.9134 - accuracy: 0.6061 - precision: 0.9375 - recall: 0.3703 - val_loss: 0.7199 - val_accuracy: 0.5882 - val_precision: 1.0000 - val_recall: 0.3864\n",
            "Epoch 452/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.8904 - accuracy: 0.6212 - precision: 0.9479 - recall: 0.3585 - val_loss: 0.5941 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.3864\n",
            "Epoch 453/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.7433 - accuracy: 0.7121 - precision: 0.9688 - recall: 0.4294 - val_loss: 0.6793 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 454/500\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.8414 - accuracy: 0.6364 - precision: 0.9062 - recall: 0.4247 - val_loss: 0.7494 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 455/500\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.8696 - accuracy: 0.6212 - precision: 0.9062 - recall: 0.4286 - val_loss: 0.7595 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4706\n",
            "Epoch 456/500\n",
            "3/3 [==============================] - 0s 36ms/step - loss: 0.8496 - accuracy: 0.6515 - precision: 0.9062 - recall: 0.4250 - val_loss: 0.6952 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 457/500\n",
            "3/3 [==============================] - 0s 41ms/step - loss: 0.7581 - accuracy: 0.6515 - precision: 0.9583 - recall: 0.3851 - val_loss: 0.6806 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 458/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.7548 - accuracy: 0.6364 - precision: 0.7708 - recall: 0.3297 - val_loss: 0.7149 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4000\n",
            "Epoch 459/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.7622 - accuracy: 0.6667 - precision: 0.9375 - recall: 0.4816 - val_loss: 0.6420 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.3864\n",
            "Epoch 460/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.7886 - accuracy: 0.6667 - precision: 0.9583 - recall: 0.3660 - val_loss: 0.6534 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 461/500\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.8447 - accuracy: 0.7121 - precision: 0.9688 - recall: 0.4257 - val_loss: 0.6585 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 462/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.8046 - accuracy: 0.6970 - precision: 0.9792 - recall: 0.4864 - val_loss: 0.6055 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 463/500\n",
            "3/3 [==============================] - 0s 40ms/step - loss: 0.7362 - accuracy: 0.6970 - precision: 0.9896 - recall: 0.4377 - val_loss: 0.5693 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 464/500\n",
            "3/3 [==============================] - 0s 42ms/step - loss: 0.6962 - accuracy: 0.7273 - precision: 0.9896 - recall: 0.4098 - val_loss: 0.6106 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 465/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.7714 - accuracy: 0.6818 - precision: 0.9375 - recall: 0.3855 - val_loss: 0.8145 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 466/500\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.8910 - accuracy: 0.6061 - precision: 0.9271 - recall: 0.3768 - val_loss: 0.6737 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 467/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.8009 - accuracy: 0.6818 - precision: 0.9479 - recall: 0.4744 - val_loss: 0.5484 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 468/500\n",
            "3/3 [==============================] - 0s 38ms/step - loss: 0.6981 - accuracy: 0.7424 - precision: 0.9479 - recall: 0.4271 - val_loss: 0.5209 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.4474\n",
            "Epoch 469/500\n",
            "3/3 [==============================] - 0s 37ms/step - loss: 0.7067 - accuracy: 0.6515 - precision: 0.9792 - recall: 0.4089 - val_loss: 0.5422 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 470/500\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.7582 - accuracy: 0.6515 - precision: 0.9271 - recall: 0.4216 - val_loss: 0.5932 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 471/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.7926 - accuracy: 0.6212 - precision: 0.9167 - recall: 0.3652 - val_loss: 0.5959 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 472/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.7437 - accuracy: 0.6515 - precision: 0.9583 - recall: 0.4231 - val_loss: 0.5762 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 473/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.7035 - accuracy: 0.6818 - precision: 0.9688 - recall: 0.3773 - val_loss: 0.5771 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 474/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.6866 - accuracy: 0.7424 - precision: 0.9792 - recall: 0.4892 - val_loss: 0.5485 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 475/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.6882 - accuracy: 0.7424 - precision: 0.9792 - recall: 0.4305 - val_loss: 0.5448 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 476/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.7090 - accuracy: 0.7121 - precision: 0.9792 - recall: 0.4055 - val_loss: 0.5327 - val_accuracy: 0.8235 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 477/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6935 - accuracy: 0.7273 - precision: 0.9792 - recall: 0.4019 - val_loss: 0.5207 - val_accuracy: 0.7059 - val_precision: 0.8824 - val_recall: 0.3947\n",
            "Epoch 478/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.7031 - accuracy: 0.6970 - precision: 0.9688 - recall: 0.4852 - val_loss: 0.5226 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 479/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.7259 - accuracy: 0.6667 - precision: 0.9792 - recall: 0.4387 - val_loss: 0.5505 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 480/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.7327 - accuracy: 0.6212 - precision: 0.9792 - recall: 0.4404 - val_loss: 0.5060 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 481/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.6787 - accuracy: 0.7121 - precision: 0.9688 - recall: 0.4309 - val_loss: 0.4668 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 482/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.6983 - accuracy: 0.6970 - precision: 0.9583 - recall: 0.4854 - val_loss: 0.4972 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 483/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.7777 - accuracy: 0.6364 - precision: 0.9375 - recall: 0.3895 - val_loss: 0.5032 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4048\n",
            "Epoch 484/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.7450 - accuracy: 0.6667 - precision: 0.9375 - recall: 0.3928 - val_loss: 0.4523 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 485/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.7201 - accuracy: 0.6818 - precision: 0.9583 - recall: 0.3988 - val_loss: 0.4460 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 486/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.6981 - accuracy: 0.6970 - precision: 0.9688 - recall: 0.4082 - val_loss: 0.4727 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 487/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.6968 - accuracy: 0.7273 - precision: 0.9583 - recall: 0.3822 - val_loss: 0.5489 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 488/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.7010 - accuracy: 0.7121 - precision: 0.9583 - recall: 0.3816 - val_loss: 0.5557 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 489/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.7106 - accuracy: 0.6818 - precision: 0.9688 - recall: 0.3879 - val_loss: 0.6403 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4250\n",
            "Epoch 490/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.8501 - accuracy: 0.6364 - precision: 0.9479 - recall: 0.4767 - val_loss: 0.6603 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4103\n",
            "Epoch 491/500\n",
            "3/3 [==============================] - 0s 22ms/step - loss: 0.7963 - accuracy: 0.6667 - precision: 0.9479 - recall: 0.3921 - val_loss: 0.5769 - val_accuracy: 0.7647 - val_precision: 0.9412 - val_recall: 0.4444\n",
            "Epoch 492/500\n",
            "3/3 [==============================] - 0s 24ms/step - loss: 0.7385 - accuracy: 0.6364 - precision: 0.9375 - recall: 0.4006 - val_loss: 0.7185 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4211\n",
            "Epoch 493/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.8543 - accuracy: 0.6212 - precision: 0.9375 - recall: 0.4334 - val_loss: 0.6819 - val_accuracy: 0.7059 - val_precision: 0.9412 - val_recall: 0.4324\n",
            "Epoch 494/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.7499 - accuracy: 0.6970 - precision: 0.9375 - recall: 0.4289 - val_loss: 0.6099 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 495/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.7282 - accuracy: 0.6515 - precision: 0.9375 - recall: 0.3730 - val_loss: 0.5452 - val_accuracy: 0.8235 - val_precision: 1.0000 - val_recall: 0.4146\n",
            "Epoch 496/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.7556 - accuracy: 0.6667 - precision: 0.9583 - recall: 0.4351 - val_loss: 0.4994 - val_accuracy: 0.7647 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 497/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 0.7319 - accuracy: 0.7273 - precision: 0.8021 - recall: 0.3582 - val_loss: 0.4805 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 498/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.6974 - accuracy: 0.6818 - precision: 0.9583 - recall: 0.4074 - val_loss: 0.5368 - val_accuracy: 0.7059 - val_precision: 1.0000 - val_recall: 0.4359\n",
            "Epoch 499/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.7443 - accuracy: 0.6970 - precision: 0.9688 - recall: 0.4084 - val_loss: 0.5711 - val_accuracy: 0.6471 - val_precision: 1.0000 - val_recall: 0.4595\n",
            "Epoch 500/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.7535 - accuracy: 0.6364 - precision: 0.9688 - recall: 0.4063 - val_loss: 0.5533 - val_accuracy: 0.6471 - val_precision: 0.9412 - val_recall: 0.4211\n"
          ]
        }
      ],
      "source": [
        "max_len = X_train.shape[1]\n",
        "\n",
        "EPOCHS = 500\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "model = nn_model(max_len)\n",
        "history = check_model(model, X_train, y_train, X_test, y_test, EPOCHS, BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "2337c77a",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "2337c77a",
        "outputId": "2b651ba5-c64d-496b-d9c0-3ac96df44e96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     epoch      loss  accuracy  precision    recall  val_loss  val_accuracy  \\\n",
              "0        1  1.384475  0.303030   0.312500  0.177414  1.351782      0.352941   \n",
              "1        2  1.362787  0.348485   0.427083  0.211699  1.328585      0.352941   \n",
              "2        3  1.348565  0.333333   0.729167  0.369261  1.328346      0.352941   \n",
              "3        4  1.344986  0.333333   0.385417  0.207273  1.324584      0.352941   \n",
              "4        5  1.337576  0.333333   0.697917  0.364176  1.327833      0.352941   \n",
              "..     ...       ...       ...        ...       ...       ...           ...   \n",
              "495    496  0.755570  0.666667   0.958333  0.435052  0.499447      0.764706   \n",
              "496    497  0.731928  0.727273   0.802083  0.358219  0.480451      0.705882   \n",
              "497    498  0.697359  0.681818   0.958333  0.407357  0.536825      0.705882   \n",
              "498    499  0.744342  0.696970   0.968750  0.408378  0.571141      0.647059   \n",
              "499    500  0.753476  0.636364   0.968750  0.406285  0.553261      0.647059   \n",
              "\n",
              "     val_precision  val_recall  \n",
              "0         0.764706    0.382353  \n",
              "1         0.705882    0.363636  \n",
              "2         0.764706    0.382353  \n",
              "3         0.705882    0.363636  \n",
              "4         0.705882    0.363636  \n",
              "..             ...         ...  \n",
              "495       1.000000    0.435897  \n",
              "496       1.000000    0.435897  \n",
              "497       1.000000    0.435897  \n",
              "498       1.000000    0.459459  \n",
              "499       0.941176    0.421053  \n",
              "\n",
              "[500 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d1d68d1-1a4f-4e26-8ec2-97f48f092877\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>1.384475</td>\n",
              "      <td>0.303030</td>\n",
              "      <td>0.312500</td>\n",
              "      <td>0.177414</td>\n",
              "      <td>1.351782</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.382353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>1.362787</td>\n",
              "      <td>0.348485</td>\n",
              "      <td>0.427083</td>\n",
              "      <td>0.211699</td>\n",
              "      <td>1.328585</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>1.348565</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.729167</td>\n",
              "      <td>0.369261</td>\n",
              "      <td>1.328346</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>0.382353</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>1.344986</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.385417</td>\n",
              "      <td>0.207273</td>\n",
              "      <td>1.324584</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>1.337576</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.697917</td>\n",
              "      <td>0.364176</td>\n",
              "      <td>1.327833</td>\n",
              "      <td>0.352941</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>0.363636</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>496</td>\n",
              "      <td>0.755570</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.435052</td>\n",
              "      <td>0.499447</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.435897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>497</td>\n",
              "      <td>0.731928</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.802083</td>\n",
              "      <td>0.358219</td>\n",
              "      <td>0.480451</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.435897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>498</td>\n",
              "      <td>0.697359</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.407357</td>\n",
              "      <td>0.536825</td>\n",
              "      <td>0.705882</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.435897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>499</td>\n",
              "      <td>0.744342</td>\n",
              "      <td>0.696970</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.408378</td>\n",
              "      <td>0.571141</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.459459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>500</td>\n",
              "      <td>0.753476</td>\n",
              "      <td>0.636364</td>\n",
              "      <td>0.968750</td>\n",
              "      <td>0.406285</td>\n",
              "      <td>0.553261</td>\n",
              "      <td>0.647059</td>\n",
              "      <td>0.941176</td>\n",
              "      <td>0.421053</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>500 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d1d68d1-1a4f-4e26-8ec2-97f48f092877')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0d1d68d1-1a4f-4e26-8ec2-97f48f092877 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0d1d68d1-1a4f-4e26-8ec2-97f48f092877');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "hist_df = pd.DataFrame(history.history)\n",
        "hist_df['epoch'] = hist_df.index + 1\n",
        "cols = list(hist_df.columns)\n",
        "cols = [cols[-1]] + cols[:-1]\n",
        "hist_df = hist_df[cols]\n",
        "hist_df.head(500)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "112ff3c1",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "112ff3c1",
        "outputId": "fbaf9a9e-7ca5-44b2-f434-a0df39e7438d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     epoch      loss  accuracy  precision    recall  val_loss  val_accuracy  \\\n",
              "484    485  0.720052  0.681818   0.958333  0.398817  0.445988      0.764706   \n",
              "\n",
              "     val_precision  val_recall  \n",
              "484            1.0    0.435897  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-279dabd8-fb24-4814-9353-5eb98820524e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>epoch</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>val_precision</th>\n",
              "      <th>val_recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>485</td>\n",
              "      <td>0.720052</td>\n",
              "      <td>0.681818</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>0.398817</td>\n",
              "      <td>0.445988</td>\n",
              "      <td>0.764706</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.435897</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-279dabd8-fb24-4814-9353-5eb98820524e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-279dabd8-fb24-4814-9353-5eb98820524e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-279dabd8-fb24-4814-9353-5eb98820524e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "values_of_best_model = hist_df[hist_df.val_loss == hist_df.val_loss.min()]\n",
        "values_of_best_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "e2605d67",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2605d67",
        "outputId": "1c0fbe0d-fa0e-4c8a-dd08-13d747b5b04d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_6 (Dense)             (None, 32)                672       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 4)                 68        \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 4)                 0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15,828\n",
            "Trainable params: 15,828\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "6fb9520c",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "6fb9520c"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "d50ed9a3",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d50ed9a3",
        "outputId": "019523de-9b80-48ed-d389-7b09a467e931"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[4.74e-01 5.15e-01 6.16e-01 2.16e-01]\n",
            " [7.83e-01 7.47e-01 1.16e-01 7.41e-01]\n",
            " [9.67e-01 7.40e-01 3.92e-02 4.06e-01]\n",
            " [1.74e-01 5.74e-01 7.98e-01 1.18e-01]\n",
            " [9.78e-01 8.52e-01 1.42e-02 6.44e-01]\n",
            " [6.93e-01 6.91e-01 2.21e-01 4.14e-01]\n",
            " [9.92e-01 9.58e-01 2.73e-03 7.05e-01]\n",
            " [1.09e-01 7.92e-01 7.70e-01 8.18e-03]\n",
            " [9.86e-01 9.13e-01 7.00e-03 6.12e-01]\n",
            " [9.96e-01 9.75e-01 1.13e-03 7.98e-01]\n",
            " [2.79e-01 7.57e-01 7.79e-01 1.93e-02]\n",
            " [3.87e-03 9.98e-01 8.60e-01 2.72e-06]\n",
            " [4.26e-01 4.72e-01 4.68e-01 4.39e-01]\n",
            " [1.11e-01 8.95e-01 7.60e-01 2.20e-03]\n",
            " [1.04e-01 6.11e-01 7.54e-02 1.00e+00]\n",
            " [1.22e-01 8.93e-01 7.58e-01 1.78e-03]\n",
            " [8.00e-01 6.47e-01 5.50e-02 9.37e-01]]\n"
          ]
        }
      ],
      "source": [
        " # predict test data\n",
        "y_pred= model.predict(X_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "46925a36",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46925a36",
        "outputId": "53081a7d-397f-48d3-cd03-5666c93aa616"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.61581564,\n",
              " 0.7831664,\n",
              " 0.9671242,\n",
              " 0.7984506,\n",
              " 0.978135,\n",
              " 0.6932492,\n",
              " 0.99156165,\n",
              " 0.7917658,\n",
              " 0.9863403,\n",
              " 0.99583274,\n",
              " 0.7785554,\n",
              " 0.99846494,\n",
              " 0.4716571,\n",
              " 0.89506555,\n",
              " 0.9997823,\n",
              " 0.89313626]"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "predict = []\n",
        "for i in range(0, 16):\n",
        "    predict.append(max(y_pred[i]))\n",
        "predict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "51844188",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "51844188"
      },
      "outputs": [],
      "source": [
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "4864b62d",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "4864b62d",
        "outputId": "1570b09a-26d0-444c-f053-95bcccee3477"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(cnf_matrix,\n",
        "                      classes=['Normal', 'RS', 'MAS', 'WS'],\n",
        "                      normalize=False,\n",
        "                      title='Confusion matrix, with normalization')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "d8b9a523",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8b9a523",
        "outputId": "17dd06ce-1796-4c1d-b872-53d380e3399a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.86      1.00      0.92         6\n",
            "          RS       0.60      0.43      0.50         7\n",
            "         MAS       0.00      0.00      0.00         1\n",
            "          WS       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.65        17\n",
            "   macro avg       0.61      0.52      0.56        17\n",
            "weighted avg       0.73      0.65      0.67        17\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_test.argmax(axis=1),\n",
        "                            y_pred.argmax(axis=1),\n",
        "                            target_names=['Normal', 'RS', 'MAS', 'WS']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "6a43e7bc",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "id": "6a43e7bc",
        "outputId": "33797b44-72a1-4905-b651-be0cd59796b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Energy_0    Corr_0  Homogen_0   Contrast_0     ASM_0  \\\n",
              "0           0  0.238833  0.517603   0.412533  3069.396847  0.057041   \n",
              "1           0  0.238353  0.512358   0.413436  3262.862123  0.056812   \n",
              "2           0  0.259169  0.445380   0.457163  3189.128320  0.067168   \n",
              "3           0  0.269625  0.548643   0.496141  3177.300241  0.072697   \n",
              "4           0  0.262031  0.443838   0.461995  3248.030262  0.068660   \n",
              "\n",
              "   Energy_45   Corr_45  Homogen_45  Contrast_45  ...  Homogen_90  Contrast_90  \\\n",
              "0   0.232840  0.481561    0.384189  3294.214195  ...    0.379124  3528.956028   \n",
              "1   0.242940  0.525515    0.433085  3173.205623  ...    0.367355  3774.753721   \n",
              "2   0.262902  0.466383    0.471457  3070.517608  ...    0.523060  2503.627934   \n",
              "3   0.252457  0.419631    0.438557  4074.419555  ...    0.421847  4255.804873   \n",
              "4   0.266288  0.473357    0.478816  3078.603990  ...    0.577084  2064.272280   \n",
              "\n",
              "     ASM_90  Energy_135  Corr_135  Homogen_135  Contrast_135   ASM_135  \\\n",
              "0  0.057041    0.242723  0.514698     0.431989   3083.943518  0.057041   \n",
              "1  0.056812    0.230253  0.464397     0.376618   3582.181970  0.056812   \n",
              "2  0.067168    0.263560  0.471281     0.475134   3042.272336  0.067168   \n",
              "3  0.072697    0.251784  0.413907     0.434164   4114.603695  0.072697   \n",
              "4  0.068660    0.269411  0.490361     0.489698   2979.088552  0.068660   \n",
              "\n",
              "   output             filenames  \n",
              "0       0  dataset/0/fish_0.jpg  \n",
              "1       0  dataset/0/fish_1.jpg  \n",
              "2       0  dataset/0/fish_3.jpg  \n",
              "3       0  dataset/0/fish_2.jpg  \n",
              "4       0  dataset/0/fish_6.jpg  \n",
              "\n",
              "[5 rows x 23 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-687523a8-a68f-4b4c-88fd-a53d3341663f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Energy_0</th>\n",
              "      <th>Corr_0</th>\n",
              "      <th>Homogen_0</th>\n",
              "      <th>Contrast_0</th>\n",
              "      <th>ASM_0</th>\n",
              "      <th>Energy_45</th>\n",
              "      <th>Corr_45</th>\n",
              "      <th>Homogen_45</th>\n",
              "      <th>Contrast_45</th>\n",
              "      <th>...</th>\n",
              "      <th>Homogen_90</th>\n",
              "      <th>Contrast_90</th>\n",
              "      <th>ASM_90</th>\n",
              "      <th>Energy_135</th>\n",
              "      <th>Corr_135</th>\n",
              "      <th>Homogen_135</th>\n",
              "      <th>Contrast_135</th>\n",
              "      <th>ASM_135</th>\n",
              "      <th>output</th>\n",
              "      <th>filenames</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.238833</td>\n",
              "      <td>0.517603</td>\n",
              "      <td>0.412533</td>\n",
              "      <td>3069.396847</td>\n",
              "      <td>0.057041</td>\n",
              "      <td>0.232840</td>\n",
              "      <td>0.481561</td>\n",
              "      <td>0.384189</td>\n",
              "      <td>3294.214195</td>\n",
              "      <td>...</td>\n",
              "      <td>0.379124</td>\n",
              "      <td>3528.956028</td>\n",
              "      <td>0.057041</td>\n",
              "      <td>0.242723</td>\n",
              "      <td>0.514698</td>\n",
              "      <td>0.431989</td>\n",
              "      <td>3083.943518</td>\n",
              "      <td>0.057041</td>\n",
              "      <td>0</td>\n",
              "      <td>dataset/0/fish_0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0.238353</td>\n",
              "      <td>0.512358</td>\n",
              "      <td>0.413436</td>\n",
              "      <td>3262.862123</td>\n",
              "      <td>0.056812</td>\n",
              "      <td>0.242940</td>\n",
              "      <td>0.525515</td>\n",
              "      <td>0.433085</td>\n",
              "      <td>3173.205623</td>\n",
              "      <td>...</td>\n",
              "      <td>0.367355</td>\n",
              "      <td>3774.753721</td>\n",
              "      <td>0.056812</td>\n",
              "      <td>0.230253</td>\n",
              "      <td>0.464397</td>\n",
              "      <td>0.376618</td>\n",
              "      <td>3582.181970</td>\n",
              "      <td>0.056812</td>\n",
              "      <td>0</td>\n",
              "      <td>dataset/0/fish_1.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0.259169</td>\n",
              "      <td>0.445380</td>\n",
              "      <td>0.457163</td>\n",
              "      <td>3189.128320</td>\n",
              "      <td>0.067168</td>\n",
              "      <td>0.262902</td>\n",
              "      <td>0.466383</td>\n",
              "      <td>0.471457</td>\n",
              "      <td>3070.517608</td>\n",
              "      <td>...</td>\n",
              "      <td>0.523060</td>\n",
              "      <td>2503.627934</td>\n",
              "      <td>0.067168</td>\n",
              "      <td>0.263560</td>\n",
              "      <td>0.471281</td>\n",
              "      <td>0.475134</td>\n",
              "      <td>3042.272336</td>\n",
              "      <td>0.067168</td>\n",
              "      <td>0</td>\n",
              "      <td>dataset/0/fish_3.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0.269625</td>\n",
              "      <td>0.548643</td>\n",
              "      <td>0.496141</td>\n",
              "      <td>3177.300241</td>\n",
              "      <td>0.072697</td>\n",
              "      <td>0.252457</td>\n",
              "      <td>0.419631</td>\n",
              "      <td>0.438557</td>\n",
              "      <td>4074.419555</td>\n",
              "      <td>...</td>\n",
              "      <td>0.421847</td>\n",
              "      <td>4255.804873</td>\n",
              "      <td>0.072697</td>\n",
              "      <td>0.251784</td>\n",
              "      <td>0.413907</td>\n",
              "      <td>0.434164</td>\n",
              "      <td>4114.603695</td>\n",
              "      <td>0.072697</td>\n",
              "      <td>0</td>\n",
              "      <td>dataset/0/fish_2.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0.262031</td>\n",
              "      <td>0.443838</td>\n",
              "      <td>0.461995</td>\n",
              "      <td>3248.030262</td>\n",
              "      <td>0.068660</td>\n",
              "      <td>0.266288</td>\n",
              "      <td>0.473357</td>\n",
              "      <td>0.478816</td>\n",
              "      <td>3078.603990</td>\n",
              "      <td>...</td>\n",
              "      <td>0.577084</td>\n",
              "      <td>2064.272280</td>\n",
              "      <td>0.068660</td>\n",
              "      <td>0.269411</td>\n",
              "      <td>0.490361</td>\n",
              "      <td>0.489698</td>\n",
              "      <td>2979.088552</td>\n",
              "      <td>0.068660</td>\n",
              "      <td>0</td>\n",
              "      <td>dataset/0/fish_6.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 23 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-687523a8-a68f-4b4c-88fd-a53d3341663f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-687523a8-a68f-4b4c-88fd-a53d3341663f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-687523a8-a68f-4b4c-88fd-a53d3341663f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "ytest = dt['output']\n",
        "xtest = dt.drop(columns=['Unnamed: 0', 'output', 'filenames'])\n",
        "xtest = preprocessing.StandardScaler().fit(xtest).transform(xtest.astype(float))\n",
        "dt.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "d07d76e2",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d07d76e2",
        "outputId": "993dcd75-7852-461a-fe8b-b875142253dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " categorical label : \n",
            " [0 1 2 3]\n",
            "\n",
            "\n",
            " one hot encoding for sample 0 : \n",
            " [1. 0. 0. 0.]\n"
          ]
        }
      ],
      "source": [
        "le = LabelEncoder()\n",
        "le.fit(dt[\"output\"].values)\n",
        "\n",
        "print(\" categorical label : \\n\", le.classes_)\n",
        "\n",
        "y2 = le.transform(dt['output'].values)\n",
        "y2 = to_categorical(y2)\n",
        "\n",
        "print(\"\\n\\n one hot encoding for sample 0 : \\n\", y2[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "fe2de98e",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fe2de98e"
      },
      "outputs": [],
      "source": [
        "y2test = y2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "6f5b07c3",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f5b07c3",
        "outputId": "157b98d3-afda-4579-c6ef-d62a3f8cdaf4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((81, 20), (81, 4))"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "xtest.shape, y2test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "700c388f",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "700c388f"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "id": "f8aa0712",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f8aa0712",
        "outputId": "cecfc510-dca8-430f-8e87-4eb6d3d704ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[7.13e-11 5.80e-01 2.31e-01 1.00e+00]\n",
            " [3.12e-19 1.15e-04 1.00e+00 1.00e+00]\n",
            " [8.85e-01 1.00e+00 6.25e-23 1.00e+00]\n",
            " [1.00e+00 1.00e+00 0.00e+00 1.00e+00]\n",
            " [2.68e-01 1.00e+00 7.91e-22 1.00e+00]\n",
            " [7.72e-09 1.00e+00 9.80e-01 1.81e-13]\n",
            " [1.00e+00 1.00e+00 2.34e-24 1.00e+00]\n",
            " [1.00e+00 1.00e+00 0.00e+00 1.00e+00]\n",
            " [9.63e-01 1.00e+00 4.05e-23 1.00e+00]\n",
            " [1.00e+00 1.00e+00 0.00e+00 1.00e+00]\n",
            " [1.03e-12 1.00e+00 9.98e-01 1.04e-33]\n",
            " [1.00e+00 1.00e+00 2.28e-30 1.00e+00]\n",
            " [9.84e-01 1.00e+00 8.86e-01 2.55e-15]\n",
            " [1.95e-15 1.00e+00 9.99e-01 3.10e-11]\n",
            " [3.22e-27 1.81e-02 1.00e+00 1.00e+00]\n",
            " [1.00e+00 1.00e+00 0.00e+00 1.00e+00]\n",
            " [2.27e-37 1.00e+00 1.00e+00 4.27e-03]\n",
            " [1.17e-35 1.00e+00 1.00e+00 2.46e-06]\n",
            " [2.59e-06 1.00e+00 9.95e-01 0.00e+00]\n",
            " [5.86e-25 1.00e+00 1.00e+00 4.23e-01]\n",
            " [6.75e-08 1.00e+00 2.52e-18 1.00e+00]\n",
            " [1.00e+00 1.00e+00 2.42e-38 1.00e+00]\n",
            " [1.12e-15 1.00e+00 1.60e-06 1.00e+00]\n",
            " [1.00e+00 1.00e+00 0.00e+00 1.00e+00]\n",
            " [3.26e-29 1.45e-01 1.00e+00 1.00e+00]\n",
            " [5.35e-23 1.00e+00 1.00e+00 4.52e-04]\n",
            " [1.73e-29 1.00e+00 1.00e+00 8.61e-27]\n",
            " [1.00e+00 1.00e+00 3.01e-36 1.00e+00]\n",
            " [9.98e-04 1.00e+00 1.14e-25 1.00e+00]\n",
            " [4.59e-04 1.00e+00 9.88e-25 1.00e+00]\n",
            " [9.56e-01 1.00e+00 1.64e-36 1.00e+00]\n",
            " [5.64e-20 1.00e+00 1.00e+00 9.46e-05]\n",
            " [1.00e+00 1.00e+00 4.09e-11 9.93e-01]\n",
            " [1.01e-22 1.00e+00 1.00e+00 3.41e-32]\n",
            " [2.69e-04 1.00e+00 5.31e-19 1.00e+00]\n",
            " [4.70e-10 1.00e+00 9.93e-01 1.11e-25]\n",
            " [8.45e-16 1.00e+00 9.98e-01 7.10e-20]\n",
            " [2.87e-26 1.00e+00 1.00e+00 6.50e-24]\n",
            " [4.77e-14 1.00e+00 9.94e-01 3.57e-30]\n",
            " [2.35e-25 1.00e+00 1.00e+00 0.00e+00]\n",
            " [1.84e-30 1.00e+00 1.00e+00 6.47e-32]\n",
            " [3.43e-22 1.00e+00 1.00e+00 1.00e+00]\n",
            " [4.91e-20 1.00e+00 9.58e-01 1.00e+00]\n",
            " [1.57e-15 1.00e+00 6.99e-04 1.00e+00]\n",
            " [1.99e-27 1.00e+00 1.00e+00 0.00e+00]\n",
            " [1.20e-17 1.00e+00 9.98e-01 6.98e-13]\n",
            " [1.05e-12 1.00e+00 9.96e-01 6.61e-19]\n",
            " [2.76e-15 1.00e+00 2.38e-19 1.00e+00]\n",
            " [3.30e-18 1.00e+00 1.00e+00 1.77e-29]\n",
            " [9.36e-13 1.00e+00 9.97e-01 6.78e-28]\n",
            " [1.99e-08 1.00e+00 1.00e+00 5.84e-06]\n",
            " [9.72e-13 1.00e+00 4.99e-09 1.00e+00]\n",
            " [3.46e-21 9.93e-02 1.00e+00 1.00e+00]\n",
            " [6.65e-27 1.87e-05 1.00e+00 1.00e+00]\n",
            " [7.27e-29 1.00e+00 1.00e+00 9.65e-01]\n",
            " [5.15e-08 1.00e+00 1.88e-28 1.00e+00]\n",
            " [1.92e-06 1.00e+00 9.62e-32 1.00e+00]\n",
            " [5.26e-04 1.00e+00 2.88e-12 1.00e+00]\n",
            " [8.00e-15 1.00e+00 2.87e-01 1.00e+00]\n",
            " [0.00e+00 9.37e-02 1.00e+00 1.00e+00]\n",
            " [1.00e+00 1.00e+00 0.00e+00 1.00e+00]\n",
            " [9.17e-04 1.00e+00 6.64e-02 1.00e+00]\n",
            " [1.73e-37 2.74e-06 1.00e+00 1.00e+00]\n",
            " [1.00e+00 1.00e+00 9.61e-30 1.00e+00]\n",
            " [4.31e-16 1.00e+00 4.67e-01 1.00e+00]\n",
            " [4.07e-31 1.00e+00 1.00e+00 2.95e-25]\n",
            " [2.37e-25 1.00e+00 1.00e+00 4.82e-20]\n",
            " [6.41e-26 1.00e+00 1.00e+00 1.81e-08]\n",
            " [2.61e-35 1.00e+00 1.00e+00 3.28e-11]\n",
            " [1.89e-27 1.00e+00 1.00e+00 1.15e-11]\n",
            " [1.25e-23 1.00e+00 1.00e+00 8.67e-28]\n",
            " [3.64e-38 1.00e+00 1.00e+00 8.78e-10]\n",
            " [1.28e-09 1.00e+00 9.81e-01 5.16e-16]\n",
            " [9.85e-23 1.00e+00 1.00e+00 7.87e-30]\n",
            " [1.87e-13 1.00e+00 9.93e-01 2.01e-32]\n",
            " [5.94e-33 1.00e+00 1.00e+00 8.77e-19]\n",
            " [4.12e-19 1.00e+00 9.99e-01 2.07e-15]\n",
            " [2.23e-08 1.00e+00 2.41e-06 1.00e+00]\n",
            " [5.15e-32 1.00e+00 1.00e+00 4.16e-28]\n",
            " [2.78e-05 1.00e+00 2.02e-13 1.00e+00]\n",
            " [9.16e-18 1.00e+00 9.98e-01 3.98e-26]]\n"
          ]
        }
      ],
      "source": [
        "ypredict = model.predict(xtest)\n",
        "print(ypredict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "id": "5221124e",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "5221124e"
      },
      "outputs": [],
      "source": [
        "# Compute confusion matrix\n",
        "cnf_matrix = confusion_matrix(y2test.argmax(axis=1), ypredict.argmax(axis=1))\n",
        "np.set_printoptions(precision=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "id": "b60b90b4",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 729
        },
        "id": "b60b90b4",
        "outputId": "d4f50f01-7cf9-4f2d-9080-a52c5af854cd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Plot non-normalized confusion matrix\n",
        "plot_confusion_matrix(cnf_matrix,\n",
        "                      classes=['Normal', 'RS', 'MAS', 'WS'],\n",
        "                      normalize=False,\n",
        "                      title='Confusion matrix, with normalization')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "id": "f55e4bfd",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f55e4bfd",
        "outputId": "01a0fba5-2afe-4bc2-dbae-b5bf45702940"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Normal       0.67      0.31      0.42        26\n",
            "          RS       0.40      0.92      0.55        25\n",
            "         MAS       0.00      0.00      0.00        16\n",
            "          WS       0.50      0.07      0.12        14\n",
            "\n",
            "    accuracy                           0.40        81\n",
            "   macro avg       0.39      0.32      0.28        81\n",
            "weighted avg       0.42      0.40      0.33        81\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y2test.argmax(axis=1),\n",
        "                            ypredict.argmax(axis=1),\n",
        "                            target_names=['Normal', 'RS', 'MAS', 'WS']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qj4Gj6RGfYQv",
        "outputId": "b39475ae-c942-458d-dac3-6f0433338777"
      },
      "id": "qj4Gj6RGfYQv",
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: gradio in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.7/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: markdown-it-py[linkify,plugins] in /usr/local/lib/python3.7/dist-packages (from gradio) (2.1.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from gradio) (1.3.5)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.7/dist-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: h11<0.13,>=0.11 in /usr/local/lib/python3.7/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gradio) (3.2.2)\n",
            "Requirement already satisfied: orjson in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from gradio) (6.0)\n",
            "Requirement already satisfied: analytics-python in /usr/local/lib/python3.7/dist-packages (from gradio) (1.4.0)\n",
            "Requirement already satisfied: pycryptodome in /usr/local/lib/python3.7/dist-packages (from gradio) (3.15.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.7/dist-packages (from gradio) (0.23.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gradio) (2.23.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from gradio) (2022.8.2)\n",
            "Requirement already satisfied: paramiko in /usr/local/lib/python3.7/dist-packages (from gradio) (2.11.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from gradio) (7.1.2)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.7/dist-packages (from gradio) (0.18.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from gradio) (2.11.3)\n",
            "Requirement already satisfied: websockets in /usr/local/lib/python3.7/dist-packages (from gradio) (10.3)\n",
            "Requirement already satisfied: python-multipart in /usr/local/lib/python3.7/dist-packages (from gradio) (0.0.5)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from gradio) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gradio) (1.21.6)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.7/dist-packages (from gradio) (0.85.0)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.7/dist-packages (from gradio) (1.9.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.0.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (2.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (4.1.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (22.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (6.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->gradio) (1.8.1)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.7/dist-packages (from yarl<2.0,>=1.0->aiohttp->gradio) (2.10)\n",
            "Requirement already satisfied: python-dateutil>2.1 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (2.8.2)\n",
            "Requirement already satisfied: backoff==1.10.0 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.10.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.15.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.7/dist-packages (from analytics-python->gradio) (1.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gradio) (1.24.3)\n",
            "Requirement already satisfied: starlette==0.20.4 in /usr/local/lib/python3.7/dist-packages (from fastapi->gradio) (0.20.4)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from starlette==0.20.4->fastapi->gradio) (3.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.7/dist-packages (from anyio<5,>=3.4.0->starlette==0.20.4->fastapi->gradio) (1.3.0)\n",
            "Requirement already satisfied: httpcore<0.16.0,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (0.15.0)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.7/dist-packages (from httpx->gradio) (1.5.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->gradio) (2.0.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (0.1.2)\n",
            "Requirement already satisfied: linkify-it-py~=1.0 in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (1.0.3)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.7/dist-packages (from markdown-it-py[linkify,plugins]->gradio) (0.3.0)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.7/dist-packages (from linkify-it-py~=1.0->markdown-it-py[linkify,plugins]->gradio) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gradio) (1.4.4)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gradio) (2022.2.1)\n",
            "Requirement already satisfied: cryptography>=2.5 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (38.0.1)\n",
            "Requirement already satisfied: pynacl>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (1.5.0)\n",
            "Requirement already satisfied: bcrypt>=3.1.3 in /usr/local/lib/python3.7/dist-packages (from paramiko->gradio) (4.0.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.5->paramiko->gradio) (1.15.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.5->paramiko->gradio) (2.21)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from uvicorn->gradio) (7.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "fd3ca9a2",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "fd3ca9a2"
      },
      "outputs": [],
      "source": [
        "import gradio as gr\n",
        "import cv2\n",
        "\n",
        "from sklearn.cluster import KMeans\n",
        "from skimage.feature import greycomatrix, greycoprops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "708539d2",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "708539d2"
      },
      "outputs": [],
      "source": [
        "def preprocessing(img):\n",
        "    resized = cv2.resize(img, (256, 256), Image.BICUBIC)\n",
        "    bgr = resized[:, :, ::-1].copy()\n",
        "\n",
        "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
        "    clahe = cv2.createCLAHE(clipLimit=0)\n",
        "    lab[:, :, 0] = clahe.apply(lab[:, :, 0])\n",
        "    lab[:, :, 1] = clahe.apply(lab[:, :, 1])\n",
        "    lab[:, :, 2] = clahe.apply(lab[:, :, 2])\n",
        "    bgr = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)\n",
        "    res = cv2.fastNlMeansDenoisingColored(bgr, None, 10, 10, 1, 3)\n",
        "    #bgr = cv2.bilateralFilter(bgr, 5, 1, 1)\n",
        "    return res\n",
        "\n",
        "\n",
        "def segmentation(img, online=False):\n",
        "    pre = preprocessing(img)\n",
        "    image = cv2.cvtColor(pre, cv2.COLOR_BGR2LAB)\n",
        "    image = image.reshape((256 * 256, 3))\n",
        "\n",
        "    clt = KMeans(n_clusters=5)\n",
        "    labels = clt.fit_predict(image)\n",
        "    quant = clt.cluster_centers_.astype(\"uint8\")[labels]\n",
        "    quant = quant.reshape((256, 256, 3))\n",
        "    res = image.reshape((256, 256, 3))\n",
        "\n",
        "    if online:\n",
        "        return quant\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "def gray_segmentation(img):\n",
        "    pre = preprocessing(img)\n",
        "    segmented = segmentation(pre, True)\n",
        "    bgr = cv2.cvtColor(segmented, cv2.COLOR_LAB2BGR)\n",
        "    res = cv2.cvtColor(bgr, cv2.COLOR_BGR2GRAY)\n",
        "    return res\n",
        "\n",
        "\n",
        "def extract(img, online=False):\n",
        "    image = gray_segmentation(img)\n",
        "    degs = [0, np.pi / 4, np.pi / 2, 3 * np.pi / 4]\n",
        "    post = [0, 45, 90, 135]\n",
        "    val = []\n",
        "    for i, deg in enumerate(degs):\n",
        "        GLCM = greycomatrix(image, [3], [deg])\n",
        "        energy = greycoprops(GLCM, 'energy')[0]\n",
        "        corr = greycoprops(GLCM, 'correlation')[0]\n",
        "        hom = greycoprops(GLCM, 'homogeneity')[0]\n",
        "        contr = greycoprops(GLCM, 'contrast')[0]\n",
        "        asm = greycoprops(GLCM, 'ASM')[0]\n",
        "\n",
        "        temp = [post[i], energy[0], corr[0], hom[0], contr[0], asm[0]]\n",
        "        val.append(temp)\n",
        "\n",
        "    res = pd.DataFrame(\n",
        "        np.array(val),\n",
        "        columns=['Degree', 'Contrast', 'Energy', 'Korelasi', 'ASM', 'Homogenity'],\n",
        "    )\n",
        "\n",
        "    if online:\n",
        "        return np.array(val)\n",
        "    return res\n",
        "\n",
        "\n",
        "def predict_(img):\n",
        "    feature = extract(img, True)[:, 1:]\n",
        "    # print(feature.shape)\n",
        "    target_names = ['Normal', 'RS', 'MAS', 'WS']\n",
        "    feature = feature.reshape((1, 20))\n",
        "    pred = model.predict(feature)\n",
        "\n",
        "    return target_names[pred.argmax()]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "a5d30b8d",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "a5d30b8d"
      },
      "outputs": [],
      "source": [
        "demo = gr.Blocks()\n",
        "\n",
        "with demo:\n",
        "    gr.Markdown('Step by step Demo')\n",
        "    img_input = gr.Image()\n",
        "    # with gr.Row():\n",
        "    img_preprocess = gr.Image()\n",
        "    button_preprocess = gr.Button('Preprocessing Button')\n",
        "\n",
        "    # with gr.Row():\n",
        "    img_segmentation = gr.Image()\n",
        "    button_segm = gr.Button(\"Segmentation Button\")\n",
        "\n",
        "    # with gr.Row():\n",
        "    img_grayscale = gr.Image()\n",
        "    button_gray = gr.Button(\"RGB to Grayscale Button\")\n",
        "\n",
        "    # with gr.Row():\n",
        "    data = gr.DataFrame(\n",
        "        headers=['Degree', 'Contrast', 'Energy', 'Korelasi', 'ASM', 'Homogenity'],\n",
        "        # row_count=(1, 'fixed')\n",
        "    )\n",
        "    button_extract = gr.Button('Extract Data')\n",
        "\n",
        "    output = gr.Textbox(label=\"Prediction Result\")\n",
        "    button_predict = gr.Button('Predict')\n",
        "    button_preprocess.click(preprocessing, inputs=img_input, outputs=img_preprocess)\n",
        "    button_segm.click(segmentation, inputs=img_input, outputs=img_segmentation)\n",
        "    button_gray.click(gray_segmentation, inputs=img_input, outputs=img_grayscale)\n",
        "    button_extract.click(extract, inputs=img_input, outputs=data)\n",
        "    button_predict.click(predict_, inputs=img_input, outputs=output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "ad1e9718",
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 643
        },
        "id": "ad1e9718",
        "outputId": "4cb37104-4707-4bca-fdb4-9906161fa157"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set `debug=True` in `launch()`\n",
            "Running on public URL: https://24850.gradio.app\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting, check out Spaces: https://huggingface.co/spaces\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://24850.gradio.app\" width=\"900\" height=\"500\" allow=\"autoplay; camera; microphone;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<gradio.routes.App at 0x7f762921acd0>,\n",
              " 'http://127.0.0.1:7861/',\n",
              " 'https://24850.gradio.app')"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "demo.close()\n",
        "demo.launch()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}